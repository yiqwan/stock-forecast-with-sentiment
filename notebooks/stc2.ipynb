{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import logging\n",
    "\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "import finnhub\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "sys.path.append('../') # Change the python path at runtime\n",
    "warnings.filterwarnings('ignore', category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "# Self-created modules\n",
    "from src.utils import path as path_yq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SUBJECTIVITY_API_KEY = os.environ.get('SUBJECTIVITY_API_KEY')\n",
    "POLARITY_API_KEY = os.environ.get('POLARITY_API_KEY')\n",
    "INTENSITY_API_KEY = os.environ.get('INTENSITY_API_KEY')\n",
    "FINNHUB_API_KEY = os.environ.get('FINNHUB_API_KEY')\n",
    "\n",
    "BT_START_DATE = '2023-11-01'\n",
    "BT_START_STR = '20231101'\n",
    "BT_END_DATE = '2024-01-31'\n",
    "BT_END_STR = '20240131'\n",
    "\n",
    "cur_dir = Path.cwd()\n",
    "root_dir = path_yq.get_root_dir(cur_dir)\n",
    "\n",
    "logging.basicConfig(filename=Path.joinpath(root_dir, 'logs', 'trading_system.log'),\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cln_hdl', 'cln_smr', 'cln_news',\n",
    "        'cln_hdl_lemma', 'cln_smr_lemma', 'cln_news_lemma']\n",
    "\n",
    "import ast\n",
    "\n",
    "def convert_data(row):\n",
    "    try:\n",
    "        # First, try to evaluate the row as a list\n",
    "        evaluated = ast.literal_eval(row)\n",
    "        # If the result is a list, return it directly\n",
    "        if isinstance(evaluated, list):\n",
    "            return evaluated\n",
    "        # If not, it's already the correct type (int, float, etc.)\n",
    "        return evaluated\n",
    "    except ValueError:\n",
    "        # Handle the case where the row is not a valid Python literal\n",
    "        # This could be a string that should not be converted\n",
    "        return row\n",
    "    except SyntaxError:\n",
    "        # Handle syntax errors which might occur if ast.literal_eval can't parse the string\n",
    "        return row\n",
    "    except Exception as e:\n",
    "        print(f'Exception: {e}')\n",
    "        return row\n",
    "\n",
    "cleaned_path = Path.joinpath(root_dir, 'data', 'proc', f'BA_cln_{BT_START_STR}_{BT_END_STR}.csv')\n",
    "df7 = pd.read_csv(cleaned_path, index_col=False)\n",
    "\n",
    "# Assuming 'list_column' is the name of your column containing the string representation of lists\n",
    "for col in cols:\n",
    "    df7[col] = df7[col].apply(convert_data)\n",
    "\n",
    "# pol: polarity, sub: subjectivity\n",
    "def sentic_api(text, KEY):\n",
    "    APIURL = f'https://sentic.net/api/en/{KEY}.py?text='\n",
    "\n",
    "    attempt = 0\n",
    "    max_attempt = 5\n",
    "    while attempt < 5:\n",
    "        try:\n",
    "            attempt += 1\n",
    "            # Adding a timeout of 5 seconds as an example\n",
    "            response = requests.get(APIURL + text, timeout=120)\n",
    "            # Assuming the API returns a string in the expected format\n",
    "            label = str(response.content)[2:-3]\n",
    "            return label\n",
    "        except requests.exceptions.Timeout:\n",
    "            # Handle timeout exception\n",
    "            if attempt < max_attempt: \n",
    "                print(f\"Sentic request timed out. Attempt {attempt} of {max_attempt}.\")\n",
    "            else:\n",
    "                print(\"No more retries.\") \n",
    "                return None\n",
    "        except Exception as e:\n",
    "            # Handle other requests exceptions\n",
    "            if attempt < max_attempt: \n",
    "                print(f\"Attempt {attempt} of {max_attempt}. Error: {e}\")\n",
    "            else:\n",
    "                print(\"No more retries.\")\n",
    "                return None\n",
    "\n",
    "def sentic_anal_pol(text_list):\n",
    "    polarity_list = []\n",
    "    for i in range(len(text_list)):\n",
    "        try:\n",
    "            polarity_cat = sentic_api(text_list[i], POLARITY_API_KEY) # Polarity category (positive, negative)\n",
    "            intensity = float(sentic_api(text_list[i], INTENSITY_API_KEY)) / 100\n",
    "            if polarity_cat == \"POSITIVE\":\n",
    "                polarity_list.append(intensity)\n",
    "            elif polarity_cat == \"NEGATIVE\":\n",
    "                polarity_list.append(-intensity)\n",
    "            elif polarity_cat == \"NEUTRAL\":\n",
    "                polarity_list.append(0)\n",
    "            else:\n",
    "                print(f\"Unknown polarity: {polarity_cat}\")\n",
    "            \n",
    "            print(f\"{(i + 1)}/{len(text_list)} sentic_anal_pol completed.\")\n",
    "        except Exception as e:\n",
    "            polarity_list.append(None)\n",
    "            print(f\"sentic_anal_pol exception for text: {text_list[i]}, {e}\")\n",
    "\n",
    "    print(f\"sentic_anal_pol completed.\")\n",
    "\n",
    "    return(polarity_list)\n",
    "\n",
    "def batch_sentic_anal(df):\n",
    "    for col in cols:\n",
    "        df[f'{col}_pol_stc'] = df[col].apply(sentic_anal_pol)\n",
    "        # df[f'{col}_sub_stc'] = df[col].apply(sentic_anal_sub)\n",
    "        df.to_csv(stm_path, index=False)\n",
    "\n",
    "def batch_anal(df):\n",
    "    # After performing sentiment\n",
    "    \n",
    "    batch_sentic_anal(df)\n",
    "    print('batch_sentic_anal completed.')\n",
    "\n",
    "    df.to_csv(stm_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 sentic_anal_pol completed.\n",
      "sentic_anal_pol completed.\n",
      "1/1 sentic_anal_pol completed.\n",
      "sentic_anal_pol completed.\n",
      "1/3 sentic_anal_pol completed.\n",
      "2/3 sentic_anal_pol completed.\n",
      "3/3 sentic_anal_pol completed.\n",
      "sentic_anal_pol completed.\n",
      "1/3 sentic_anal_pol completed.\n",
      "2/3 sentic_anal_pol completed.\n",
      "3/3 sentic_anal_pol completed.\n",
      "sentic_anal_pol completed.\n",
      "1/19 sentic_anal_pol completed.\n",
      "2/19 sentic_anal_pol completed.\n",
      "3/19 sentic_anal_pol completed.\n",
      "4/19 sentic_anal_pol completed.\n",
      "5/19 sentic_anal_pol completed.\n",
      "6/19 sentic_anal_pol completed.\n",
      "7/19 sentic_anal_pol completed.\n",
      "8/19 sentic_anal_pol completed.\n",
      "9/19 sentic_anal_pol completed.\n",
      "10/19 sentic_anal_pol completed.\n",
      "11/19 sentic_anal_pol completed.\n",
      "12/19 sentic_anal_pol completed.\n",
      "13/19 sentic_anal_pol completed.\n",
      "14/19 sentic_anal_pol completed.\n",
      "15/19 sentic_anal_pol completed.\n",
      "16/19 sentic_anal_pol completed.\n",
      "17/19 sentic_anal_pol completed.\n",
      "18/19 sentic_anal_pol completed.\n",
      "19/19 sentic_anal_pol completed.\n",
      "sentic_anal_pol completed.\n",
      "1/7 sentic_anal_pol completed.\n",
      "2/7 sentic_anal_pol completed.\n",
      "3/7 sentic_anal_pol completed.\n",
      "4/7 sentic_anal_pol completed.\n",
      "5/7 sentic_anal_pol completed.\n",
      "6/7 sentic_anal_pol completed.\n",
      "7/7 sentic_anal_pol completed.\n",
      "sentic_anal_pol completed.\n",
      "batch_sentic_anal completed.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Change columns, and pathname, and df7\n",
    "cols = ['cln_hdl_lemma', 'cln_smr_lemma', 'cln_news_lemma']\n",
    "stm_path = root_dir.joinpath('data', 'proc', f'BA_stm_stc2_{BT_START_STR}_{BT_END_STR}.csv') \n",
    "\n",
    "batch_anal(df7.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
