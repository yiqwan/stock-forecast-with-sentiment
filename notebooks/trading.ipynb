{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade\n",
    "- Swing trading/long-term trading\n",
    "    - Exposed to overnight risk (close price previous day might not equal to open \n",
    "    price next day if there are major events happening between market closure and\n",
    "    market open).\n",
    "- Assume I already have which day to long, which day to short\n",
    "- Conduct post-trade analysis\n",
    "- Refine risk management techniques (Comparing starting on 2023-12-22)\n",
    "    - Boeing: Main character in the events\n",
    "        - Stock -18.61%\n",
    "\n",
    "    - Direct competitors\n",
    "        - Airbus (EPA: AIR): Boeing's primary competitor in commercial aircraft manufacturing\n",
    "            - Stock +5.93%\n",
    "        - Lockhead Martin (LMT): More focused on defense but also compete in aerospace\n",
    "    - Suppliers\n",
    "        - General Electric (GE): Supplies engines for Boeing aircraft\n",
    "            - Have presence in aviation, healthcare, power, renewable energy\n",
    "            - Doesn't seem to be affected\n",
    "            - Can also supply engines to other aircraft manufacturers (effect on\n",
    "            stock price is complicated)\n",
    "    - Customers\n",
    "        - Alaska Airlines (ALK): Main airline involved\n",
    "            - Stock -11.73%\n",
    "        - American Airlines (UAL - NasdaqGS)\n",
    "            - Stock -4.91%\n",
    "        - Delta Air Lines (DAL)\n",
    "            - -11.73%\n",
    "        - Southwest Airlines\n",
    "- Trading timing (NYSE) vs news timing\n",
    "    - The news was updated on January 18, 2024, at 4:36 AM GMT+8, which translates to January 17, 2024, at 3:36 PM Eastern Time (since GMT+8 is 13 hours ahead of Eastern Time). Since the NYSE closes at 4:00 PM ET, this news would have come out just before the market close.\n",
    "    - Difference stock exchanges might operate at different timings also\n",
    "- No training and validation - straight go to validation (backtesting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import finnhub\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path    \n",
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import typing\n",
    "\n",
    "sys.path.append('../') # Change the python path at runtime\n",
    "\n",
    "# Self-created modules\n",
    "from src.utils import path as path_yq\n",
    "from src.backtesting import Backtest, Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "load_dotenv()\n",
    "POLYGON_API_KEY = os.environ.get('POLYGON_API_KEY')\n",
    "\n",
    "BT_START_DATE = '2023-11-01'\n",
    "BT_START_STR = '20231101'\n",
    "BT_END_DATE = '2024-01-31'\n",
    "BT_END_STR = '20240131'\n",
    "\n",
    "cur_dir = Path.cwd()\n",
    "root_dir = path_yq.get_root_dir(cur_dir)\n",
    "\n",
    "logging.basicConfig(filename=Path.joinpath(root_dir, 'logs', 'trading_system.log'),\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "stm_techs = ['stc', 'blob', 'sid', 'bert', 'finbert']\n",
    "contents = ['cln_hdl', 'cln_smr', 'cln_news']\n",
    "lemmas = ['', 'lemma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Tick Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polygon docs: https://polygon.io/docs/stocks/get_v2_aggs_ticker__stocksticker__range__multiplier___timespan___from___to\n",
    "\n",
    "- FIXME: The timings include those in pre-market hours\n",
    "- The timestamp is in ms, not sec\n",
    "\n",
    "Similar to download data codes\n",
    "TODO: Assumption: assume other stocks share the same timezone\n",
    "\n",
    "- The data is incomplete (not every minute)\n",
    "24265\t47739.0\t217.6996\t217.6800\t217.7000\t217.7000\t217.6800\t1705096560000\t21\t2024-01-12 21:56:00\n",
    "24266\t171.0\t217.5423\t217.5000\t217.5000\t217.5000\t217.5000\t1705096800000\t5\t2024-01-12 22:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f\"https://api.polygon.io/v2/aggs/ticker/BA/range/1/minute/{BT_START_DATE}/{BT_END_DATE}?adjusted=true&sort=asc&limit=50000&apiKey={POLYGON_API_KEY}\"\n",
    "\n",
    "# Make the GET request\n",
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the request was successful\n",
    "if resp.status_code == 200:\n",
    "    # Convert the 'results' list to a DataFrame\n",
    "    df = pd.DataFrame(resp.json().get('results'))\n",
    "\n",
    "    # Rename the columns to more descriptive names\n",
    "    column_mapping = {\n",
    "        \"v\": \"Volume\",\n",
    "        \"vw\": \"VWAP\",\n",
    "        \"o\": \"Open\",\n",
    "        \"c\": \"Close\",\n",
    "        \"h\": \"High\",\n",
    "        \"l\": \"Low\",\n",
    "        \"t\": \"Timestamp\",\n",
    "        \"n\": \"Transactions\"\n",
    "        # Add more mappings as necessary\n",
    "    }\n",
    "\n",
    "    df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "    # Optionally, convert the 'Timestamp' column from Unix milliseconds to a datetime format\n",
    "    df['Datetime'] = pd.to_datetime(df['Timestamp'], unit='ms')\n",
    "\n",
    "    # Display the updated DataFrame\n",
    "    print(df)\n",
    "else:\n",
    "    # Handle errors (e.g., logging, raising an exception)\n",
    "    print(f\"Error fetching data: {resp.status_code}, {resp.text}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boeing open high low close data\n",
    "raw_path = Path.joinpath(root_dir, 'data', 'raw', f'BA_OHLC_{BT_START_STR}_{BT_END_STR}.csv')\n",
    "df.to_csv(raw_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yahoo (Outdated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ticker list\n",
    "ticker_list = ['BA']\n",
    "\n",
    "# Fetch the data\n",
    "dl_data = yf.download(ticker_list, start=BT_START_DATE, end=BT_END_DATE) # Auto adjust is false\n",
    "\n",
    "dl_data = pd.DataFrame(dl_data)\n",
    "data = dl_data.drop(columns=['Close'], axis=1)\n",
    "data = data.rename(columns={'Adj Close': 'Close'})\n",
    "display(data.isna().sum(axis=0)) # Axis=0: along the indices, row-wise opertaion\n",
    "# Gives the sum for rows in a column\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame(data.index.strftime('%Y-%m-%d'))\n",
    "# dates.to_csv(\"trading_dates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After performing sentiment\n",
    "stm_path = root_dir.joinpath('data', 'proc', 'boeing_stm_20231101_to_20240131.csv')\n",
    "news = pd.read_csv(stm_path, index_col=False)\n",
    "news2 = news[['datetime2', 'news_pol_blob']]\n",
    "news2\n",
    "\n",
    "news2.plot()\n",
    "# # data['Sentiment'] = np.random.random(len(data)) * 2 - 1\n",
    "# display(len(data))\n",
    "# sentiment = np.array([0, -1, -0.8, 0, 0, 0]) # Put -1 on 01-05 (Before the whole thing Boeing case appeared after market closed on 01-05 to prepare to trade for 01-08)\n",
    "# data['Sentiment'] = sentiment\n",
    "# display(data.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure datetime2 in news2 is in pandas datetime format\n",
    "news2['datetime2'] = pd.to_datetime(news2['datetime2'])\n",
    "\n",
    "# Assuming data.index is already a DatetimeIndex, no need to convert it again\n",
    "# Just ensure it's sorted\n",
    "data.sort_index(inplace=True)\n",
    "\n",
    "# Function to find the closest previous date in data for each date in news2\n",
    "def find_closest_previous_date(target_date, date_index):\n",
    "    previous_dates = date_index[date_index <= target_date]\n",
    "    if not previous_dates.empty:\n",
    "        return previous_dates.max()\n",
    "    else:\n",
    "        return pd.NaT  # Return Not-A-Time (NaT) if no previous date is found\n",
    "\n",
    "# Apply the function to each date in news2['datetime2']\n",
    "closest_dates = news2['datetime2'].apply(lambda x: find_closest_previous_date(x, data.index))\n",
    "\n",
    "# Add this closest date information to news2\n",
    "news2['closest_date'] = closest_dates\n",
    "news2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Need to think of how to combine the data (might have many neutral etc.)\n",
    "# as_index will retain closest_date\n",
    "news3 = news2.groupby('closest_date', as_index=False)['news_pol_blob'].mean().reset_index(drop=True) \n",
    "news3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(data, news3, left_on='Date', right_on='closest_date', how='left')\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean for 2 lines only\n",
    "merged2 = merged.dropna().reset_index(drop=True)\n",
    "merged2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_data(row):\n",
    "    \"\"\"\n",
    "    A function from sentiment.ipynb.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # First, try to evaluate the row as a list\n",
    "        evaluated = ast.literal_eval(row)\n",
    "        # If the result is a list, return it directly\n",
    "        if isinstance(evaluated, list):\n",
    "            return evaluated\n",
    "        # If not, it's already the correct type (int, float, etc.)\n",
    "        return evaluated\n",
    "    except ValueError:\n",
    "        # Handle the case where the row is not a valid Python literal\n",
    "        # This could be a string that should not be converted\n",
    "        return row\n",
    "    except SyntaxError:\n",
    "        # Handle syntax errors which might occur if ast.literal_eval can't parse the string\n",
    "        return row\n",
    "    except Exception as e:\n",
    "        print(f'Exception: {e}')\n",
    "        return row\n",
    "\n",
    "score_path = root_dir.joinpath('data', 'proc', f'BA_score_{BT_START_STR}_{BT_END_STR}.csv') \n",
    "df9 = pd.read_csv(score_path, index_col=False)\n",
    "\n",
    "# Apply the conversion function to each specified column\n",
    "for col in df9.columns:\n",
    "    df9[col] = df9[col].apply(convert_data)\n",
    "df9['datetime2'] = pd.to_datetime(df9['datetime2'])\n",
    "\n",
    "# print(df8.equals(df7))\n",
    "# print(type(df8['datetime2'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Volume</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>991.0</td>\n",
       "      <td>186.6991</td>\n",
       "      <td>186.6200</td>\n",
       "      <td>186.8000</td>\n",
       "      <td>186.8000</td>\n",
       "      <td>186.6200</td>\n",
       "      <td>1698829200000</td>\n",
       "      <td>31</td>\n",
       "      <td>2023-11-01 09:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>410.0</td>\n",
       "      <td>186.8187</td>\n",
       "      <td>186.8200</td>\n",
       "      <td>186.8200</td>\n",
       "      <td>186.8200</td>\n",
       "      <td>186.8200</td>\n",
       "      <td>1698829560000</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-11-01 09:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1289.0</td>\n",
       "      <td>187.6589</td>\n",
       "      <td>187.5900</td>\n",
       "      <td>187.7000</td>\n",
       "      <td>187.7000</td>\n",
       "      <td>187.5900</td>\n",
       "      <td>1698830040000</td>\n",
       "      <td>29</td>\n",
       "      <td>2023-11-01 09:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>535.0</td>\n",
       "      <td>188.1637</td>\n",
       "      <td>187.8400</td>\n",
       "      <td>187.9600</td>\n",
       "      <td>187.9600</td>\n",
       "      <td>187.8400</td>\n",
       "      <td>1698830100000</td>\n",
       "      <td>34</td>\n",
       "      <td>2023-11-01 09:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>442.0</td>\n",
       "      <td>188.8297</td>\n",
       "      <td>188.7900</td>\n",
       "      <td>188.7900</td>\n",
       "      <td>188.7900</td>\n",
       "      <td>188.7900</td>\n",
       "      <td>1698830160000</td>\n",
       "      <td>27</td>\n",
       "      <td>2023-11-01 09:16:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31393</th>\n",
       "      <td>1009.0</td>\n",
       "      <td>199.7495</td>\n",
       "      <td>199.7500</td>\n",
       "      <td>199.7500</td>\n",
       "      <td>199.7500</td>\n",
       "      <td>199.7500</td>\n",
       "      <td>1706658600000</td>\n",
       "      <td>7</td>\n",
       "      <td>2024-01-30 23:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31394</th>\n",
       "      <td>250.0</td>\n",
       "      <td>199.6644</td>\n",
       "      <td>199.6500</td>\n",
       "      <td>199.6500</td>\n",
       "      <td>199.6500</td>\n",
       "      <td>199.6500</td>\n",
       "      <td>1706658720000</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-30 23:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31395</th>\n",
       "      <td>315.0</td>\n",
       "      <td>199.7283</td>\n",
       "      <td>199.7369</td>\n",
       "      <td>199.7369</td>\n",
       "      <td>199.7369</td>\n",
       "      <td>199.7369</td>\n",
       "      <td>1706658960000</td>\n",
       "      <td>11</td>\n",
       "      <td>2024-01-30 23:56:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31396</th>\n",
       "      <td>503.0</td>\n",
       "      <td>199.7896</td>\n",
       "      <td>199.7999</td>\n",
       "      <td>199.7999</td>\n",
       "      <td>199.7999</td>\n",
       "      <td>199.7999</td>\n",
       "      <td>1706659080000</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-01-30 23:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31397</th>\n",
       "      <td>417.0</td>\n",
       "      <td>199.7056</td>\n",
       "      <td>199.7000</td>\n",
       "      <td>199.7000</td>\n",
       "      <td>199.7000</td>\n",
       "      <td>199.7000</td>\n",
       "      <td>1706659200000</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-01-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31398 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Volume      VWAP      Open     Close      High       Low  \\\n",
       "0       991.0  186.6991  186.6200  186.8000  186.8000  186.6200   \n",
       "1       410.0  186.8187  186.8200  186.8200  186.8200  186.8200   \n",
       "2      1289.0  187.6589  187.5900  187.7000  187.7000  187.5900   \n",
       "3       535.0  188.1637  187.8400  187.9600  187.9600  187.8400   \n",
       "4       442.0  188.8297  188.7900  188.7900  188.7900  188.7900   \n",
       "...       ...       ...       ...       ...       ...       ...   \n",
       "31393  1009.0  199.7495  199.7500  199.7500  199.7500  199.7500   \n",
       "31394   250.0  199.6644  199.6500  199.6500  199.6500  199.6500   \n",
       "31395   315.0  199.7283  199.7369  199.7369  199.7369  199.7369   \n",
       "31396   503.0  199.7896  199.7999  199.7999  199.7999  199.7999   \n",
       "31397   417.0  199.7056  199.7000  199.7000  199.7000  199.7000   \n",
       "\n",
       "           Timestamp  Transactions            Datetime  \n",
       "0      1698829200000            31 2023-11-01 09:00:00  \n",
       "1      1698829560000             5 2023-11-01 09:06:00  \n",
       "2      1698830040000            29 2023-11-01 09:14:00  \n",
       "3      1698830100000            34 2023-11-01 09:15:00  \n",
       "4      1698830160000            27 2023-11-01 09:16:00  \n",
       "...              ...           ...                 ...  \n",
       "31393  1706658600000             7 2024-01-30 23:50:00  \n",
       "31394  1706658720000             4 2024-01-30 23:52:00  \n",
       "31395  1706658960000            11 2024-01-30 23:56:00  \n",
       "31396  1706659080000             6 2024-01-30 23:58:00  \n",
       "31397  1706659200000             4 2024-01-31 00:00:00  \n",
       "\n",
       "[31398 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch and sort tick data\n",
    "# Boeing open high low close data\n",
    "raw_path = Path.joinpath(root_dir, 'data', 'raw', f'BA_OHLC_{BT_START_STR}_{BT_END_STR}.csv')\n",
    "tick = pd.read_csv(raw_path, index_col=False)\n",
    "tick['Datetime'] = pd.to_datetime(tick['Datetime'])\n",
    "tick = tick.sort_values(by='Datetime')\n",
    "\n",
    "# Make sure the tick data is within backtest date range\n",
    "tick = tick[(tick['Datetime'] >= BT_START_DATE) & (tick['Datetime'] <= BT_END_DATE)]\n",
    "tick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING. Previous date not found for 2023-11-01 05:39:51\n",
      "0       2023-11-01 09:00:00\n",
      "1       2023-11-01 09:06:00\n",
      "2       2023-11-01 09:14:00\n",
      "3       2023-11-01 09:15:00\n",
      "4       2023-11-01 09:16:00\n",
      "                ...        \n",
      "31393   2024-01-30 23:50:00\n",
      "31394   2024-01-30 23:52:00\n",
      "31395   2024-01-30 23:56:00\n",
      "31396   2024-01-30 23:58:00\n",
      "31397   2024-01-31 00:00:00\n",
      "Name: Datetime, Length: 31398, dtype: datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>datetime2</th>\n",
       "      <th>cln_hdl</th>\n",
       "      <th>cln_smr</th>\n",
       "      <th>cln_news</th>\n",
       "      <th>cln_hdl_lemma</th>\n",
       "      <th>cln_smr_lemma</th>\n",
       "      <th>cln_news_lemma</th>\n",
       "      <th>cln_hdl_pol_blob</th>\n",
       "      <th>cln_smr_pol_blob</th>\n",
       "      <th>...</th>\n",
       "      <th>cln_hdl_lemma_pol_bert_score</th>\n",
       "      <th>cln_smr_lemma_pol_bert_score</th>\n",
       "      <th>cln_news_lemma_pol_bert_score</th>\n",
       "      <th>cln_hdl_pol_finbert_score</th>\n",
       "      <th>cln_smr_pol_finbert_score</th>\n",
       "      <th>cln_news_pol_finbert_score</th>\n",
       "      <th>cln_hdl_lemma_pol_finbert_score</th>\n",
       "      <th>cln_smr_lemma_pol_finbert_score</th>\n",
       "      <th>cln_news_lemma_pol_finbert_score</th>\n",
       "      <th>closest_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123559928</td>\n",
       "      <td>2023-11-01 05:39:51</td>\n",
       "      <td>[Ford, GM bumped to buy Boeing gets 2 upgrades...</td>\n",
       "      <td>[Goldman Sachs upgraded Simon Property Group (...</td>\n",
       "      <td>[Investing.com — Here is your Pro Recap of the...</td>\n",
       "      <td>[Ford , GM bumped buy Boeing get 2 upgrade : 4...</td>\n",
       "      <td>[Goldman Sachs upgraded Simon Property Group (...</td>\n",
       "      <td>[Investing.com — Pro Recap biggest analyst pic...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727060</td>\n",
       "      <td>-0.689266</td>\n",
       "      <td>-0.340141</td>\n",
       "      <td>0.894530</td>\n",
       "      <td>0.549459</td>\n",
       "      <td>0.360264</td>\n",
       "      <td>0.641842</td>\n",
       "      <td>0.836147</td>\n",
       "      <td>0.400344</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123544219</td>\n",
       "      <td>2023-11-01 11:39:06</td>\n",
       "      <td>[UPDATE 2-Spirit Aero cuts 737 fuselage delive...</td>\n",
       "      <td>[Spirit AeroSystems on Wednesday announced $10...</td>\n",
       "      <td>[(Adjusts shares in paragraph 5, adds Airbus c...</td>\n",
       "      <td>[UPDATE 2-Spirit Aero cut 737 fuselage deliver...</td>\n",
       "      <td>[Spirit AeroSystems Wednesday announced $ 101 ...</td>\n",
       "      <td>[( Adjusts share paragraph 5 , add Airbus comm...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0, 0.0625, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142053</td>\n",
       "      <td>-0.793133</td>\n",
       "      <td>-0.597804</td>\n",
       "      <td>-0.943793</td>\n",
       "      <td>-0.335737</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>-0.900221</td>\n",
       "      <td>-0.361670</td>\n",
       "      <td>0.448931</td>\n",
       "      <td>2023-11-01 11:39:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123566505</td>\n",
       "      <td>2023-11-01 13:30:29</td>\n",
       "      <td>[Compared to Estimates, Spirit Aerosystems (SP...</td>\n",
       "      <td>[Although the revenue and EPS for Spirit Aeros...</td>\n",
       "      <td>[For the quarter ended September 2023, Spirit ...</td>\n",
       "      <td>[Compared Estimates , Spirit Aerosystems ( SPR...</td>\n",
       "      <td>[Although revenue EPS Spirit Aerosystems ( SPR...</td>\n",
       "      <td>[quarter ended September 2023 , Spirit Aerosys...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.15]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.174489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.215470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.354270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530006</td>\n",
       "      <td>2023-11-01 13:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123545059</td>\n",
       "      <td>2023-11-01 14:21:57</td>\n",
       "      <td>[Morning Brew: AMDs Q4 Guidance Weighs on Stoc...</td>\n",
       "      <td>[Advanced Micro Devices (NASDAQ:AMD) stock was...</td>\n",
       "      <td>[Advanced Micro Devices (NASDAQ:AMD) stock was...</td>\n",
       "      <td>[Morning Brew : AMDs Q4 Guidance Weighs Stock ...</td>\n",
       "      <td>[Advanced Micro Devices ( NASDAQ : AMD ) stock...</td>\n",
       "      <td>[Advanced Micro Devices ( NASDAQ : AMD ) stock...</td>\n",
       "      <td>[-0.3]</td>\n",
       "      <td>[0.1527777777777778, 0.22727272727272727, -0.06]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.744470</td>\n",
       "      <td>-0.263412</td>\n",
       "      <td>-0.343342</td>\n",
       "      <td>-0.958961</td>\n",
       "      <td>-0.322292</td>\n",
       "      <td>-0.101700</td>\n",
       "      <td>-0.852977</td>\n",
       "      <td>-0.267872</td>\n",
       "      <td>0.130774</td>\n",
       "      <td>2023-11-01 14:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123567205</td>\n",
       "      <td>2023-11-01 22:24:31</td>\n",
       "      <td>[UPDATE 1-US Air Force blows up Minuteman III ...</td>\n",
       "      <td>[The U.S. Air Force said on Wednesday it had b...</td>\n",
       "      <td>[Nov 1 (Reuters) - The U.S. Air Force said on ...</td>\n",
       "      <td>[UPDATE 1-US Air Force blow Minuteman III test...</td>\n",
       "      <td>[U.S. Air Force said Wednesday blown Minuteman...</td>\n",
       "      <td>[Nov 1 ( Reuters ) - U.S. Air Force said Wedne...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[-0.4, -0.25, 0.0]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.733265</td>\n",
       "      <td>-0.253360</td>\n",
       "      <td>0.317687</td>\n",
       "      <td>-0.892588</td>\n",
       "      <td>-0.872526</td>\n",
       "      <td>-0.066805</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.047870</td>\n",
       "      <td>2023-11-01 22:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>125415682</td>\n",
       "      <td>2024-01-30 21:10:56</td>\n",
       "      <td>[Boeing Seen Narrowing Q4 Loss Amid 737 Max Gr...</td>\n",
       "      <td>[Dow Jones giant Boeing reports Q4 results ear...</td>\n",
       "      <td>[Dow Jones giant Boeing reports Q4 results ear...</td>\n",
       "      <td>[Boeing Seen Narrowing Q4 Loss Amid 737 Max Gr...</td>\n",
       "      <td>[Dow Jones giant Boeing report Q4 result early...</td>\n",
       "      <td>[Dow Jones giant Boeing report Q4 result early...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.05, 0.1]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.737527</td>\n",
       "      <td>-0.239781</td>\n",
       "      <td>-0.239781</td>\n",
       "      <td>-0.965217</td>\n",
       "      <td>-0.952749</td>\n",
       "      <td>-0.952749</td>\n",
       "      <td>-0.965217</td>\n",
       "      <td>-0.944420</td>\n",
       "      <td>-0.944420</td>\n",
       "      <td>2024-01-30 21:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>125415680</td>\n",
       "      <td>2024-01-30 22:23:48</td>\n",
       "      <td>[Hawaiian Airlines ekes out Q4 revenue beat, e...</td>\n",
       "      <td>[Hawaiian Holdings (HA) — the parent company o...</td>\n",
       "      <td>[Hawaiian Holdings (HA) — the parent company o...</td>\n",
       "      <td>[Hawaiian Airlines ekes Q4 revenue beat , earn...</td>\n",
       "      <td>[Hawaiian Holdings ( HA ) — parent company Haw...</td>\n",
       "      <td>[Hawaiian Holdings ( HA ) — parent company Haw...</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[-0.06666666666666667, -0.15555555555555559, 0...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.776986</td>\n",
       "      <td>-0.258785</td>\n",
       "      <td>-0.224460</td>\n",
       "      <td>-0.381478</td>\n",
       "      <td>-0.922368</td>\n",
       "      <td>-0.055458</td>\n",
       "      <td>-0.667220</td>\n",
       "      <td>-0.905073</td>\n",
       "      <td>0.281039</td>\n",
       "      <td>2024-01-30 22:21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>125415679</td>\n",
       "      <td>2024-01-30 22:39:00</td>\n",
       "      <td>[Boeings Earnings Are Coming., Investors Are W...</td>\n",
       "      <td>[The list of points to watch when the jet make...</td>\n",
       "      <td>[The number of watch items in Boeings fourth-q...</td>\n",
       "      <td>[Boeings Earnings Coming ., Investors Watching...</td>\n",
       "      <td>[list point watch jet maker report latest resu...</td>\n",
       "      <td>[number watch item Boeings fourth-quarter repo...</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[0.225]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698278</td>\n",
       "      <td>0.720234</td>\n",
       "      <td>0.151111</td>\n",
       "      <td>0.856519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.730035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2024-01-30 22:38:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>125417521</td>\n",
       "      <td>2024-01-30 23:03:43</td>\n",
       "      <td>[Boeing was once known for safety and engineer...</td>\n",
       "      <td>[Part of the fuselage blowing off shortly afte...</td>\n",
       "      <td>[Part of the fuselage blowing off shortly afte...</td>\n",
       "      <td>[Boeing known safety engineering ., critic say...</td>\n",
       "      <td>[Part fuselage blowing shortly takeoff , leavi...</td>\n",
       "      <td>[Part fuselage blowing shortly takeoff , leavi...</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[0.0, -0.1587179487179487, 0.0, -0.125]</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262539</td>\n",
       "      <td>-0.442463</td>\n",
       "      <td>-0.278902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.928406</td>\n",
       "      <td>-0.508453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.912366</td>\n",
       "      <td>-0.404513</td>\n",
       "      <td>2024-01-30 23:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>125417520</td>\n",
       "      <td>2024-01-30 23:39:02</td>\n",
       "      <td>[Ryanair will take as many Boeing MAX 10s as i...</td>\n",
       "      <td>[Ryanair will take as many Boeing MAX 10 aircr...</td>\n",
       "      <td>[WARSAW (Reuters) - Ryanair will take as many ...</td>\n",
       "      <td>[Ryanair take many Boeing MAX 10 get , say CEO]</td>\n",
       "      <td>[Ryanair take many Boeing MAX 10 aircraft get ...</td>\n",
       "      <td>[WARSAW ( Reuters ) - Ryanair take many Boeing...</td>\n",
       "      <td>[0.5]</td>\n",
       "      <td>[0.5, -0.016666666666666666, 0.25]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659246</td>\n",
       "      <td>-0.561462</td>\n",
       "      <td>-0.422191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.343098</td>\n",
       "      <td>-0.279701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295564</td>\n",
       "      <td>-0.062199</td>\n",
       "      <td>2024-01-30 23:39:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id           datetime2  \\\n",
       "0    123559928 2023-11-01 05:39:51   \n",
       "1    123544219 2023-11-01 11:39:06   \n",
       "2    123566505 2023-11-01 13:30:29   \n",
       "3    123545059 2023-11-01 14:21:57   \n",
       "4    123567205 2023-11-01 22:24:31   \n",
       "..         ...                 ...   \n",
       "546  125415682 2024-01-30 21:10:56   \n",
       "547  125415680 2024-01-30 22:23:48   \n",
       "548  125415679 2024-01-30 22:39:00   \n",
       "549  125417521 2024-01-30 23:03:43   \n",
       "550  125417520 2024-01-30 23:39:02   \n",
       "\n",
       "                                               cln_hdl  \\\n",
       "0    [Ford, GM bumped to buy Boeing gets 2 upgrades...   \n",
       "1    [UPDATE 2-Spirit Aero cuts 737 fuselage delive...   \n",
       "2    [Compared to Estimates, Spirit Aerosystems (SP...   \n",
       "3    [Morning Brew: AMDs Q4 Guidance Weighs on Stoc...   \n",
       "4    [UPDATE 1-US Air Force blows up Minuteman III ...   \n",
       "..                                                 ...   \n",
       "546  [Boeing Seen Narrowing Q4 Loss Amid 737 Max Gr...   \n",
       "547  [Hawaiian Airlines ekes out Q4 revenue beat, e...   \n",
       "548  [Boeings Earnings Are Coming., Investors Are W...   \n",
       "549  [Boeing was once known for safety and engineer...   \n",
       "550  [Ryanair will take as many Boeing MAX 10s as i...   \n",
       "\n",
       "                                               cln_smr  \\\n",
       "0    [Goldman Sachs upgraded Simon Property Group (...   \n",
       "1    [Spirit AeroSystems on Wednesday announced $10...   \n",
       "2    [Although the revenue and EPS for Spirit Aeros...   \n",
       "3    [Advanced Micro Devices (NASDAQ:AMD) stock was...   \n",
       "4    [The U.S. Air Force said on Wednesday it had b...   \n",
       "..                                                 ...   \n",
       "546  [Dow Jones giant Boeing reports Q4 results ear...   \n",
       "547  [Hawaiian Holdings (HA) — the parent company o...   \n",
       "548  [The list of points to watch when the jet make...   \n",
       "549  [Part of the fuselage blowing off shortly afte...   \n",
       "550  [Ryanair will take as many Boeing MAX 10 aircr...   \n",
       "\n",
       "                                              cln_news  \\\n",
       "0    [Investing.com — Here is your Pro Recap of the...   \n",
       "1    [(Adjusts shares in paragraph 5, adds Airbus c...   \n",
       "2    [For the quarter ended September 2023, Spirit ...   \n",
       "3    [Advanced Micro Devices (NASDAQ:AMD) stock was...   \n",
       "4    [Nov 1 (Reuters) - The U.S. Air Force said on ...   \n",
       "..                                                 ...   \n",
       "546  [Dow Jones giant Boeing reports Q4 results ear...   \n",
       "547  [Hawaiian Holdings (HA) — the parent company o...   \n",
       "548  [The number of watch items in Boeings fourth-q...   \n",
       "549  [Part of the fuselage blowing off shortly afte...   \n",
       "550  [WARSAW (Reuters) - Ryanair will take as many ...   \n",
       "\n",
       "                                         cln_hdl_lemma  \\\n",
       "0    [Ford , GM bumped buy Boeing get 2 upgrade : 4...   \n",
       "1    [UPDATE 2-Spirit Aero cut 737 fuselage deliver...   \n",
       "2    [Compared Estimates , Spirit Aerosystems ( SPR...   \n",
       "3    [Morning Brew : AMDs Q4 Guidance Weighs Stock ...   \n",
       "4    [UPDATE 1-US Air Force blow Minuteman III test...   \n",
       "..                                                 ...   \n",
       "546  [Boeing Seen Narrowing Q4 Loss Amid 737 Max Gr...   \n",
       "547  [Hawaiian Airlines ekes Q4 revenue beat , earn...   \n",
       "548  [Boeings Earnings Coming ., Investors Watching...   \n",
       "549  [Boeing known safety engineering ., critic say...   \n",
       "550    [Ryanair take many Boeing MAX 10 get , say CEO]   \n",
       "\n",
       "                                         cln_smr_lemma  \\\n",
       "0    [Goldman Sachs upgraded Simon Property Group (...   \n",
       "1    [Spirit AeroSystems Wednesday announced $ 101 ...   \n",
       "2    [Although revenue EPS Spirit Aerosystems ( SPR...   \n",
       "3    [Advanced Micro Devices ( NASDAQ : AMD ) stock...   \n",
       "4    [U.S. Air Force said Wednesday blown Minuteman...   \n",
       "..                                                 ...   \n",
       "546  [Dow Jones giant Boeing report Q4 result early...   \n",
       "547  [Hawaiian Holdings ( HA ) — parent company Haw...   \n",
       "548  [list point watch jet maker report latest resu...   \n",
       "549  [Part fuselage blowing shortly takeoff , leavi...   \n",
       "550  [Ryanair take many Boeing MAX 10 aircraft get ...   \n",
       "\n",
       "                                        cln_news_lemma cln_hdl_pol_blob  \\\n",
       "0    [Investing.com — Pro Recap biggest analyst pic...            [0.0]   \n",
       "1    [( Adjusts share paragraph 5 , add Airbus comm...            [0.0]   \n",
       "2    [quarter ended September 2023 , Spirit Aerosys...            [0.0]   \n",
       "3    [Advanced Micro Devices ( NASDAQ : AMD ) stock...           [-0.3]   \n",
       "4    [Nov 1 ( Reuters ) - U.S. Air Force said Wedne...            [0.0]   \n",
       "..                                                 ...              ...   \n",
       "546  [Dow Jones giant Boeing report Q4 result early...            [0.0]   \n",
       "547  [Hawaiian Holdings ( HA ) — parent company Haw...            [0.0]   \n",
       "548  [number watch item Boeings fourth-quarter repo...       [0.0, 0.0]   \n",
       "549  [Part fuselage blowing shortly takeoff , leavi...       [0.0, 0.0]   \n",
       "550  [WARSAW ( Reuters ) - Ryanair take many Boeing...            [0.5]   \n",
       "\n",
       "                                      cln_smr_pol_blob  ...  \\\n",
       "0                                                [0.0]  ...   \n",
       "1                                   [0.0, 0.0625, 0.0]  ...   \n",
       "2                                               [0.15]  ...   \n",
       "3     [0.1527777777777778, 0.22727272727272727, -0.06]  ...   \n",
       "4                                   [-0.4, -0.25, 0.0]  ...   \n",
       "..                                                 ...  ...   \n",
       "546                                        [0.05, 0.1]  ...   \n",
       "547  [-0.06666666666666667, -0.15555555555555559, 0...  ...   \n",
       "548                                            [0.225]  ...   \n",
       "549            [0.0, -0.1587179487179487, 0.0, -0.125]  ...   \n",
       "550                 [0.5, -0.016666666666666666, 0.25]  ...   \n",
       "\n",
       "    cln_hdl_lemma_pol_bert_score cln_smr_lemma_pol_bert_score  \\\n",
       "0                       0.727060                    -0.689266   \n",
       "1                       0.142053                    -0.793133   \n",
       "2                       0.174489                     0.000000   \n",
       "3                      -0.744470                    -0.263412   \n",
       "4                      -0.733265                    -0.253360   \n",
       "..                           ...                          ...   \n",
       "546                    -0.737527                    -0.239781   \n",
       "547                    -0.776986                    -0.258785   \n",
       "548                     0.698278                     0.720234   \n",
       "549                    -0.262539                    -0.442463   \n",
       "550                     0.659246                    -0.561462   \n",
       "\n",
       "    cln_news_lemma_pol_bert_score cln_hdl_pol_finbert_score  \\\n",
       "0                       -0.340141                  0.894530   \n",
       "1                       -0.597804                 -0.943793   \n",
       "2                       -0.215470                  0.000000   \n",
       "3                       -0.343342                 -0.958961   \n",
       "4                        0.317687                 -0.892588   \n",
       "..                            ...                       ...   \n",
       "546                     -0.239781                 -0.965217   \n",
       "547                     -0.224460                 -0.381478   \n",
       "548                      0.151111                  0.856519   \n",
       "549                     -0.278902                  0.000000   \n",
       "550                     -0.422191                  0.000000   \n",
       "\n",
       "    cln_smr_pol_finbert_score cln_news_pol_finbert_score  \\\n",
       "0                    0.549459                   0.360264   \n",
       "1                   -0.335737                   0.295100   \n",
       "2                    0.000000                   0.354270   \n",
       "3                   -0.322292                  -0.101700   \n",
       "4                   -0.872526                  -0.066805   \n",
       "..                        ...                        ...   \n",
       "546                 -0.952749                  -0.952749   \n",
       "547                 -0.922368                  -0.055458   \n",
       "548                  0.000000                   0.000000   \n",
       "549                 -0.928406                  -0.508453   \n",
       "550                 -0.343098                  -0.279701   \n",
       "\n",
       "    cln_hdl_lemma_pol_finbert_score cln_smr_lemma_pol_finbert_score  \\\n",
       "0                          0.641842                        0.836147   \n",
       "1                         -0.900221                       -0.361670   \n",
       "2                          0.000000                        0.000000   \n",
       "3                         -0.852977                       -0.267872   \n",
       "4                          0.000000                        0.000000   \n",
       "..                              ...                             ...   \n",
       "546                       -0.965217                       -0.944420   \n",
       "547                       -0.667220                       -0.905073   \n",
       "548                        0.730035                        0.000000   \n",
       "549                        0.000000                       -0.912366   \n",
       "550                        0.000000                        0.295564   \n",
       "\n",
       "    cln_news_lemma_pol_finbert_score        closest_date  \n",
       "0                           0.400344                 NaT  \n",
       "1                           0.448931 2023-11-01 11:39:00  \n",
       "2                           0.530006 2023-11-01 13:30:00  \n",
       "3                           0.130774 2023-11-01 14:21:00  \n",
       "4                          -0.047870 2023-11-01 22:01:00  \n",
       "..                               ...                 ...  \n",
       "546                        -0.944420 2024-01-30 21:09:00  \n",
       "547                         0.281039 2024-01-30 22:21:00  \n",
       "548                         0.000000 2024-01-30 22:38:00  \n",
       "549                        -0.404513 2024-01-30 23:03:00  \n",
       "550                        -0.062199 2024-01-30 23:39:00  \n",
       "\n",
       "[551 rows x 69 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming data.index is already a DatetimeIndex, no need to convert it again\n",
    "df9['datetime2'] = pd.to_datetime(df9['datetime2'])\n",
    "tick['Datetime'] = pd.to_datetime(tick['Datetime'])\n",
    "\n",
    "# Make sure to sort first\n",
    "df9 = df9.sort_values(by='datetime2')\n",
    "tick = tick.sort_values(by='Datetime')\n",
    "\n",
    "# Function to find the closest previous date in tick for each date in news2\n",
    "def find_closest_prev_date(target_date, date_col):\n",
    "    # The information gotten at this time point can only be used in the next time point\n",
    "    prev_dates = date_col[date_col <= target_date] \n",
    "    if not prev_dates.empty:\n",
    "        return prev_dates.max()\n",
    "    else:\n",
    "        # Can happen when the news is earlier than all the tick data\n",
    "        print(f\"WARNING. Previous date not found for {target_date}\")\n",
    "        print(date_col)\n",
    "        return pd.NaT  # Return Not-A-Time (NaT) if no previous date is found\n",
    "\n",
    "# Apply the function to each date in news2['datetime2']\n",
    "closest_dates = df9['datetime2'].apply(lambda x: find_closest_prev_date(x, tick['Datetime']))\n",
    "\n",
    "# Add this closest date information to news2\n",
    "df9['closest_date'] = closest_dates\n",
    "df9.sort_values(by='datetime2')\n",
    "df9.reset_index(inplace=True, drop=True)\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the difference between datetime2 and closest_date to reduce overnight trading risks,\n",
    "# or risks caused by lack of tick data\n",
    "df9['datetime_diff'] = df9['datetime2'] - df9['closest_date']\n",
    "# Check if there is any negative difference\n",
    "print(np.sum(df9['datetime_diff'] < pd.Timedelta(0)))\n",
    "\n",
    "mask = df9['datetime_diff'] >= pd.Timedelta(5, unit='m')\n",
    "df9 = df9[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaT in find previous closest dates\n",
    "def drop_na(df):\n",
    "    # Drop all the news_content with na\n",
    "    print(f\"Before dropping na: {df.isna().sum().sum()}\")\n",
    "    df1 = df.dropna()\n",
    "    df1.reset_index(inplace=True, drop=True)\n",
    "    print(f\"After dropping na: {df.isna().sum().sum()}\")\n",
    "    return df1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_na(df9).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether there are 30 columns of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df9.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Scores between Trading Periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for stm_tech in stm_techs:\n",
    "    for lemma in lemmas:\n",
    "        for content in contents:\n",
    "            if lemma:\n",
    "                col_name = f'{content}_{lemma}_pol_{stm_tech}_score'\n",
    "\n",
    "            else:\n",
    "                col_name = f'{content}_pol_{stm_tech}_score'\n",
    "            tmp = df9.groupby('closest_date', as_index=False)[col_name].mean().reset_index(drop=True) \n",
    "            df_list.append(tmp)\n",
    "            # display(tmp)\n",
    "# print(df_list)\n",
    "\n",
    "# # Assumes df_list has at least two elements\n",
    "# merged = df_list[0]\n",
    "# for i in range(1, len(df_list)):\n",
    "#     merged = pd.merge(left=merged, right=df_list[i], on='closest_date', how='inner')\n",
    "# merged\n",
    "\n",
    "from functools import reduce\n",
    "# A simpler implementation\n",
    "merged = reduce(lambda left, right: pd.merge(left, right, on='closest_date', how='inner'), df_list)\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Tick Data and Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2 = pd.merge(left=tick, right=merged, left_on='Datetime', right_on='closest_date', how='left')\n",
    "merged2.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_path = root_dir.joinpath('data', 'proc', f'BA_merged_{BT_START_STR}_{BT_END_STR}.csv') # TODO: Change dates\n",
    "merged2.to_csv(merge_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Post-Trade Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged2[merged2.index == 1873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose col_name to describe\n",
    "merged2[col_name].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-trade analysis\n",
    "merged2[merged2['Datetime'] >= pd.to_datetime('2023-11-01 11:39:00')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtesting\n",
    "- Pros\n",
    "    - Test single strategy\n",
    "    - Have optimizer, graphs\n",
    "- Cons\n",
    "    - Cannot trade multiple assets FIXME: not applicable to portfolio\n",
    "    - Does not trade fractional shares\n",
    "https://kernc.github.io/backtesting.py/#example\n",
    "\n",
    "\n",
    "- Other backtesting framework: backtrader, zipline - both can do multi-asset trading\n",
    "- Backtrader works with Pandas DataFrames, CSV, and real-time data feeds from Interactive Brokers, Oanda, and Visual Chart. \n",
    "- 2% rule: https://www.investopedia.com/terms/t/two-percent-rule.asp#:~:text=What%20Is%20the%202%25%20Rule,capital%20on%20any%20single%20trade.\n",
    "- Try to have less than 10% of drawdown: https://www.quora.com/How-do-I-use-the-never-risk-more-than-2-rule-in-Forex-trading\n",
    "\n",
    "\n",
    "Hypothesis\n",
    "- Takes in a df from start to end, with all the ticker data (including those NA for sentiment)\n",
    "- Enters trade at 549 (My information should backfill)\n",
    "548\t308.0\t247.7006\t247.7000\t247.7000\t247.7000\t247.7000\t1704291540000\t8\t2024-01-03 14:19:00\t2024-01-03 14:19:00\t0.156808\n",
    "549\t264.0\t247.6105\t247.6000\t247.6000\t247.6000\t247.6000\t1704291780000\t9\t2024-01-03 14:23:00\tNaT\tNaN\n",
    "550\t1157.0\t247.5724\t247.6000\t247.5031\t247.6001\t247.5031\t1704291840000\t49\t2024-01-03 14:24:00\tNaT\tNaN\n",
    "- I can compare the results between lemmatization or not, and fix other variables constant\n",
    "- I can compare the results between different content and fix others constant\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_PCT = 0.02\n",
    "SL_PCT = 0.006\n",
    "RISK_PER_TRADE = 0.5\n",
    "\n",
    "\n",
    "class SimpleStmStrat(Strategy):\n",
    "    \"\"\"\n",
    "    Use a proportional amount of cash to trade with the sentiment score indicator.\n",
    "    \"\"\"\n",
    "    # Strategy class should define parameters as class variables before they can be optimized or run with.\n",
    "    col = None\n",
    "\n",
    "    # Add the parameters in init\n",
    "    def __init__(self, broker, data, **kwargs):\n",
    "        super().__init__(broker, data, **kwargs)  # Make sure the parent class can handle **kwargs appropriately\n",
    "        self.col = kwargs.get('col', self.col)\n",
    "\n",
    "    # Initialize additional indicators here if needed\n",
    "    def init(self):\n",
    "        # self.trade_size = 40 # This times the next open price cannot exceed equity\n",
    "        self.tp_pct = TP_PCT\n",
    "        self.sl_pct = SL_PCT\n",
    "        self.risk_per_trade = RISK_PER_TRADE # Maximum of the portfolio on one trade\n",
    "\n",
    "    def next(self):\n",
    "        cur_stm = self.data[self.col][-1]\n",
    "        # print(self.data['closest_date'][-1])\n",
    "        cur_price = self.data['Close'][-1]\n",
    "\n",
    "        # print(f\"-----{self.data['Datetime'][-1]}-----\")\n",
    "        # trade_size = (0.5 * (abs(cur_stm) ** 2) + 0.5) * self.risk_per_trade\n",
    "\n",
    "        # Can be around 15\n",
    "\n",
    "        # Decision is made on the time point before entry \n",
    "        # Entry Bar is the index, entry price is the open price of the next time point\n",
    "        # Not sure why exit price is not the open price at the exitBar?? Should be because of tp and sl\n",
    "\n",
    "        trade_size = self.risk_per_trade \n",
    "        if (cur_stm > 0.2): # Many losses if I don't take\n",
    "            # print(f\"Buy: {self.data['closest_date'][-1]}\")\n",
    "            self.buy(size=trade_size, sl=(1 - self.sl_pct) * cur_price, tp=(1 + self.tp_pct) * cur_price)\n",
    "            # If size is a value between 0 and 1, it is interpreted as a fraction of current available liquidity (cash plus Position.pl minus used margin). A value greater than or equal to 1 indicates an absolute number of units.\n",
    "\n",
    "        elif cur_stm < -0.2:\n",
    "            # print(f\"Sell: {self.data['closest_date'][-1]}\")\n",
    "            self.sell(size=trade_size, sl=(1 + self.sl_pct) * cur_price, tp=(1 - self.tp_pct) * cur_price)\n",
    "        else:\n",
    "            pass\n",
    "        # print(cur_stm)\n",
    "\n",
    "class RandomStrat(Strategy):\n",
    "    \"\"\"\n",
    "    A strategy that randomly trades for ttl_trade times, and if it trades,\n",
    "    the probability of buy and sell is 0.5.\n",
    "    \"\"\"\n",
    "    ttl_trade = 10\n",
    "    # Add the parameters in init\n",
    "    def __init__(self, broker, data, **kwargs):\n",
    "        super().__init__(broker, data, **kwargs)  # Make sure the parent class can handle **kwargs appropriately\n",
    "        self.ttl_trade = kwargs.get('ttl_trade', self.ttl_trade)\n",
    "        self.trade_prob = self.ttl_trade / len(self.data)\n",
    "        # print(f\"Total number of data:{len(self.data)}\")\n",
    "        \n",
    "    # Initialize additional indicators here if needed\n",
    "    def init(self):\n",
    "        self.tp_pct = TP_PCT\n",
    "        self.sl_pct = SL_PCT\n",
    "        self.risk_per_trade = RISK_PER_TRADE # Maximum of the portfolio on one trade\n",
    "\n",
    "    def next(self):\n",
    "        trade_size = self.risk_per_trade \n",
    "        cur_price = self.data['Close'][-1]\n",
    "        trade_flag = np.random.rand() < self.trade_prob\n",
    "        buy_flag = np.random.rand() > 0.5\n",
    "        if (trade_flag and buy_flag): # Many losses if I don't take\n",
    "            # print(f\"Buy: {self.data.index[-1]}\")\n",
    "            self.buy(size=trade_size, sl=(1 - self.sl_pct) * cur_price, tp=(1 + self.tp_pct) * cur_price)\n",
    "            # If size is a value between 0 and 1, it is interpreted as a fraction of current available liquidity (cash plus Position.pl minus used margin). A value greater than or equal to 1 indicates an absolute number of units.\n",
    "\n",
    "        elif (trade_flag):\n",
    "            # print(f\"Sell: {self.data.index[-1]}\")\n",
    "            self.sell(size=trade_size, sl=(1 + self.sl_pct) * cur_price, tp=(1 - self.tp_pct) * cur_price)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge_path = root_dir.joinpath('data', 'proc', f'BA_merged_{BT_START_STR}_{BT_END_STR}.csv') \n",
    "merged2 = pd.read_csv(merge_path, index_col=False)\n",
    "\n",
    "\n",
    "# TODO: Split into 3 months to analyse\n",
    "convert_data(merged2)\n",
    "merged2['Datetime'] = pd.to_datetime(merged2['Datetime'])\n",
    "\n",
    "# merged2 = merged2[(merged2['Datetime'] >= pd.to_datetime('2023-11-01')) & (merged2['Datetime'] < pd.to_datetime('2023-12-01'))]\n",
    "# merged2 = merged2[(merged2['Datetime'] >= pd.to_datetime('2023-12-01')) & (merged2['Datetime'] < pd.to_datetime('2024-01-01'))]\n",
    "# merged2 = merged2[(merged2['Datetime'] >= pd.to_datetime('2024-01-01')) & (merged2['Datetime'] < pd.to_datetime('2024-02-01'))]\n",
    "merged2 = merged2[(merged2['Datetime'] >= pd.to_datetime('2023-11-01')) & (merged2['Datetime'] < pd.to_datetime('2024-02-01'))]\n",
    "\n",
    "# TODO: Adjust interest rate based on backtesting period\n",
    "\n",
    "BACKTEST_PERIOD_ANN = 3 / 12 # 1 month\n",
    "BACKTEST_FREQUENCY_ANN = 1 / BACKTEST_PERIOD_ANN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Strat for Different Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_no_lemma_stc.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_no_lemma_stc.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_no_lemma_stc.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_lemma_stc.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_lemma_stc.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_lemma_stc.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_no_lemma_blob.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_no_lemma_blob.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_no_lemma_blob.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_lemma_blob.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_lemma_blob.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_lemma_blob.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_no_lemma_sid.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_no_lemma_sid.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_no_lemma_sid.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_lemma_sid.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_lemma_sid.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_lemma_sid.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_no_lemma_bert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_no_lemma_bert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_no_lemma_bert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_lemma_bert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_lemma_bert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_lemma_bert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_no_lemma_finbert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_no_lemma_finbert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_no_lemma_finbert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_hdl_lemma_finbert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_smr_lemma_finbert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/35484545.py:22: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/cln_news_lemma_finbert.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n"
     ]
    }
   ],
   "source": [
    "tar_dir = root_dir.joinpath('outputs', 'trade-plots')\n",
    "tar_dir.mkdir(parents=True, exist_ok=True)\n",
    "df_list = []\n",
    "\n",
    "for stm_tech in stm_techs:\n",
    "    for lemma in lemmas:\n",
    "        for content in contents:\n",
    "            results_dict = {\n",
    "                'stm_tech': stm_tech,\n",
    "                'lemma': 'No',\n",
    "                'content': content\n",
    "            }\n",
    "            if lemma:\n",
    "                col_name = f'{content}_{lemma}_pol_{stm_tech}_score'\n",
    "                filename = str(tar_dir.joinpath(f\"{content}_lemma_{stm_tech}.html\"))\n",
    "                results_dict[lemma] = 'Yes'\n",
    "            else:\n",
    "                col_name = f'{content}_pol_{stm_tech}_score'\n",
    "                filename = str(tar_dir.joinpath(f\"{content}_no_lemma_{stm_tech}.html\"))\n",
    "\n",
    "            # Running the backtest\n",
    "            bt = Backtest(\n",
    "                data=merged2, \n",
    "                strategy=SimpleStmStrat, \n",
    "                        cash=10000, \n",
    "                        margin=1,\n",
    "                        commission=.0,\n",
    "                        trade_on_close=False,\n",
    "                        hedging=True\n",
    "                        )\n",
    "            \n",
    "            results = bt.run(col=col_name)\n",
    "\n",
    "            # display(results)\n",
    "            # print(type(returns))\n",
    "            # display(returns)\n",
    "\n",
    "            bt.plot(filename=filename,\n",
    "                    results=results,\n",
    "                    plot_return=True,\n",
    "                    open_browser=False)\n",
    "            \n",
    "            results_dict.update(results.to_dict())\n",
    "            df_list.append(results_dict)\n",
    "            # results_dict['returns'] = list(returns)\n",
    "            # results_dict.update(results)\n",
    "            # df_list.append(results_dict)\n",
    "            # These are the main results that we need\n",
    "            # print(results.get('Return [%]'), results.get('Max. Drawdown [%]'), results.get('# Trades'), results.get('Win Rate [%]'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_60_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_90_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_120_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_150_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_180_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_210_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_240_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_270_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_300_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_330_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/backtesting.py:1095: FutureWarning: Index.is_numeric is deprecated. Use pandas.api.types.is_any_real_numeric_dtype instead\n",
      "  (data.index.is_numeric() and\n",
      "/var/folders/nw/_dsfxl1x5wl1p_pdmrb1y1hh0000gn/T/ipykernel_1662/1470474947.py:6: UserWarning: Data index is not datetime. Assuming simple periods, but `pd.DateTimeIndex` is advised.\n",
      "  bt = Backtest(\n",
      "INFO:bokeh.io.state:Session output file '/Users/tangyiqwan/dev/projects/quant/fyp/outputs/trade-plots/randomStrat_360_trades.html' already exists, will be overwritten.\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_drag' property; using the latest value\n",
      "  fig = gridplot(\n",
      "/Users/tangyiqwan/dev/projects/quant/fyp/notebooks/../src/backtesting/_plotting.py:660: UserWarning: found multiple competing values for 'toolbar.active_scroll' property; using the latest value\n",
      "  fig = gridplot(\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "random_df_list = []\n",
    "for ttl_trade in range(60, 390, 30):\n",
    "    # Running the backtest\n",
    "    # Pass in tick data (more opportunities to trade compared to merged data)\n",
    "    bt = Backtest(\n",
    "        data=tick, \n",
    "        strategy=RandomStrat, \n",
    "                cash=10000, \n",
    "                margin=1,\n",
    "                commission=.0,\n",
    "                trade_on_close=False,\n",
    "                hedging=True\n",
    "                )\n",
    "\n",
    "    # Estimate 10 trades\n",
    "    results = bt.run(ttl_trade=ttl_trade)\n",
    "\n",
    "    tar_dir = root_dir.joinpath('outputs', 'trade-plots')\n",
    "    tar_dir.mkdir(parents=True, exist_ok=True)\n",
    "    filename = str(tar_dir.joinpath(f\"randomStrat_{ttl_trade}_trades.html\"))\n",
    "\n",
    "    bt.plot(filename=filename,\n",
    "            results=results,\n",
    "            plot_return=True,\n",
    "            open_browser=False)\n",
    "    \n",
    "    random_df_list.append(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Exposure Time [%]</th>\n",
       "      <th>Equity Final [$]</th>\n",
       "      <th>Equity Peak [$]</th>\n",
       "      <th>Return [%]</th>\n",
       "      <th>Buy &amp; Hold Return [%]</th>\n",
       "      <th>Return (Ann.) [%]</th>\n",
       "      <th>Volatility (Ann.) [%]</th>\n",
       "      <th>Sharpe Ratio</th>\n",
       "      <th>Sortino Ratio</th>\n",
       "      <th>Calmar Ratio</th>\n",
       "      <th>Max. Drawdown [%]</th>\n",
       "      <th>Avg. Drawdown [%]</th>\n",
       "      <th>Max. Drawdown Duration</th>\n",
       "      <th>Avg. Drawdown Duration</th>\n",
       "      <th># Trades</th>\n",
       "      <th>Win Rate [%]</th>\n",
       "      <th>Best Trade [%]</th>\n",
       "      <th>Worst Trade [%]</th>\n",
       "      <th>Avg. Trade [%]</th>\n",
       "      <th>Max. Trade Duration</th>\n",
       "      <th>Avg. Trade Duration</th>\n",
       "      <th>Profit Factor</th>\n",
       "      <th>Expectancy [%]</th>\n",
       "      <th>SQN</th>\n",
       "      <th>Kelly Criterion</th>\n",
       "      <th>_strategy</th>\n",
       "      <th>_equity_curve</th>\n",
       "      <th>_trades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31.460603</td>\n",
       "      <td>10193.186035</td>\n",
       "      <td>10670.183444</td>\n",
       "      <td>1.931860</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.538604</td>\n",
       "      <td>-0.164078</td>\n",
       "      <td>24641.0</td>\n",
       "      <td>296.187500</td>\n",
       "      <td>56.0</td>\n",
       "      <td>26.785714</td>\n",
       "      <td>2.122613</td>\n",
       "      <td>-0.988631</td>\n",
       "      <td>0.083067</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>212.464286</td>\n",
       "      <td>1.200639</td>\n",
       "      <td>0.089787</td>\n",
       "      <td>0.499444</td>\n",
       "      <td>0.040906</td>\n",
       "      <td>RandomStrat(ttl_trade=60)</td>\n",
       "      <td>Equity  DrawdownPct  DrawdownDura...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>44.598382</td>\n",
       "      <td>9860.523833</td>\n",
       "      <td>10095.196224</td>\n",
       "      <td>-1.394762</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.163824</td>\n",
       "      <td>-0.684126</td>\n",
       "      <td>22942.0</td>\n",
       "      <td>2072.400000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>26.213592</td>\n",
       "      <td>6.925090</td>\n",
       "      <td>-6.651644</td>\n",
       "      <td>-0.073473</td>\n",
       "      <td>1471.0</td>\n",
       "      <td>237.203883</td>\n",
       "      <td>0.908246</td>\n",
       "      <td>-0.058197</td>\n",
       "      <td>-0.265927</td>\n",
       "      <td>-0.020142</td>\n",
       "      <td>RandomStrat(ttl_trade=90)</td>\n",
       "      <td>Equity  DrawdownPct  DrawdownDura...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice  Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>49.824830</td>\n",
       "      <td>10255.372933</td>\n",
       "      <td>10559.846397</td>\n",
       "      <td>2.553729</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.948549</td>\n",
       "      <td>-0.239334</td>\n",
       "      <td>9390.0</td>\n",
       "      <td>373.712500</td>\n",
       "      <td>113.0</td>\n",
       "      <td>29.203540</td>\n",
       "      <td>2.196074</td>\n",
       "      <td>-1.448039</td>\n",
       "      <td>0.122533</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>222.353982</td>\n",
       "      <td>1.290872</td>\n",
       "      <td>0.129670</td>\n",
       "      <td>0.527262</td>\n",
       "      <td>0.034283</td>\n",
       "      <td>RandomStrat(ttl_trade=120)</td>\n",
       "      <td>Equity  DrawdownPct  DrawdownDura...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>66.931015</td>\n",
       "      <td>10274.145036</td>\n",
       "      <td>10976.816530</td>\n",
       "      <td>2.741450</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.785679</td>\n",
       "      <td>-0.235653</td>\n",
       "      <td>16030.0</td>\n",
       "      <td>199.394737</td>\n",
       "      <td>167.0</td>\n",
       "      <td>25.748503</td>\n",
       "      <td>2.876620</td>\n",
       "      <td>-1.745474</td>\n",
       "      <td>0.027228</td>\n",
       "      <td>1883.0</td>\n",
       "      <td>239.047904</td>\n",
       "      <td>1.071923</td>\n",
       "      <td>0.033919</td>\n",
       "      <td>0.516716</td>\n",
       "      <td>0.026616</td>\n",
       "      <td>RandomStrat(ttl_trade=150)</td>\n",
       "      <td>Equity  DrawdownPct  DrawdownDura...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice  Exit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>61.621759</td>\n",
       "      <td>9182.876018</td>\n",
       "      <td>10013.517400</td>\n",
       "      <td>-8.171240</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.126044</td>\n",
       "      <td>-1.348363</td>\n",
       "      <td>31136.0</td>\n",
       "      <td>4457.000000</td>\n",
       "      <td>176.0</td>\n",
       "      <td>20.454545</td>\n",
       "      <td>2.133418</td>\n",
       "      <td>-1.293021</td>\n",
       "      <td>-0.098815</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>243.551136</td>\n",
       "      <td>0.815287</td>\n",
       "      <td>-0.093127</td>\n",
       "      <td>-2.099379</td>\n",
       "      <td>-0.107279</td>\n",
       "      <td>RandomStrat(ttl_trade=180)</td>\n",
       "      <td>Equity  DrawdownPct  DrawdownDura...</td>\n",
       "      <td>Size  EntryBar  ExitBar  EntryPrice   Exi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Start      End  Duration  Exposure Time [%]  Equity Final [$]  \\\n",
       "0    0.0  31397.0   31397.0          31.460603      10193.186035   \n",
       "1    0.0  31397.0   31397.0          44.598382       9860.523833   \n",
       "2    0.0  31397.0   31397.0          49.824830      10255.372933   \n",
       "3    0.0  31397.0   31397.0          66.931015      10274.145036   \n",
       "4    0.0  31397.0   31397.0          61.621759       9182.876018   \n",
       "\n",
       "   Equity Peak [$]  Return [%]  Buy & Hold Return [%]  Return (Ann.) [%]  \\\n",
       "0     10670.183444    1.931860               6.905782                0.0   \n",
       "1     10095.196224   -1.394762               6.905782                0.0   \n",
       "2     10559.846397    2.553729               6.905782                0.0   \n",
       "3     10976.816530    2.741450               6.905782                0.0   \n",
       "4     10013.517400   -8.171240               6.905782                0.0   \n",
       "\n",
       "   Volatility (Ann.) [%]  Sharpe Ratio  Sortino Ratio  Calmar Ratio  \\\n",
       "0                    NaN           NaN            NaN           0.0   \n",
       "1                    NaN           NaN            NaN           0.0   \n",
       "2                    NaN           NaN            NaN           0.0   \n",
       "3                    NaN           NaN            NaN           0.0   \n",
       "4                    NaN           NaN            NaN           0.0   \n",
       "\n",
       "   Max. Drawdown [%]  Avg. Drawdown [%]  Max. Drawdown Duration  \\\n",
       "0          -4.538604          -0.164078                 24641.0   \n",
       "1          -4.163824          -0.684126                 22942.0   \n",
       "2          -3.948549          -0.239334                  9390.0   \n",
       "3          -6.785679          -0.235653                 16030.0   \n",
       "4          -9.126044          -1.348363                 31136.0   \n",
       "\n",
       "   Avg. Drawdown Duration  # Trades  Win Rate [%]  Best Trade [%]  \\\n",
       "0              296.187500      56.0     26.785714        2.122613   \n",
       "1             2072.400000     103.0     26.213592        6.925090   \n",
       "2              373.712500     113.0     29.203540        2.196074   \n",
       "3              199.394737     167.0     25.748503        2.876620   \n",
       "4             4457.000000     176.0     20.454545        2.133418   \n",
       "\n",
       "   Worst Trade [%]  Avg. Trade [%]  Max. Trade Duration  Avg. Trade Duration  \\\n",
       "0        -0.988631        0.083067               1149.0           212.464286   \n",
       "1        -6.651644       -0.073473               1471.0           237.203883   \n",
       "2        -1.448039        0.122533               1155.0           222.353982   \n",
       "3        -1.745474        0.027228               1883.0           239.047904   \n",
       "4        -1.293021       -0.098815               1476.0           243.551136   \n",
       "\n",
       "   Profit Factor  Expectancy [%]       SQN  Kelly Criterion  \\\n",
       "0       1.200639        0.089787  0.499444         0.040906   \n",
       "1       0.908246       -0.058197 -0.265927        -0.020142   \n",
       "2       1.290872        0.129670  0.527262         0.034283   \n",
       "3       1.071923        0.033919  0.516716         0.026616   \n",
       "4       0.815287       -0.093127 -2.099379        -0.107279   \n",
       "\n",
       "                    _strategy  \\\n",
       "0   RandomStrat(ttl_trade=60)   \n",
       "1   RandomStrat(ttl_trade=90)   \n",
       "2  RandomStrat(ttl_trade=120)   \n",
       "3  RandomStrat(ttl_trade=150)   \n",
       "4  RandomStrat(ttl_trade=180)   \n",
       "\n",
       "                                       _equity_curve  \\\n",
       "0               Equity  DrawdownPct  DrawdownDura...   \n",
       "1               Equity  DrawdownPct  DrawdownDura...   \n",
       "2               Equity  DrawdownPct  DrawdownDura...   \n",
       "3               Equity  DrawdownPct  DrawdownDura...   \n",
       "4               Equity  DrawdownPct  DrawdownDura...   \n",
       "\n",
       "                                             _trades  \n",
       "0      Size  EntryBar  ExitBar  EntryPrice   Exit...  \n",
       "1       Size  EntryBar  ExitBar  EntryPrice  Exit...  \n",
       "2       Size  EntryBar  ExitBar  EntryPrice   Exi...  \n",
       "3       Size  EntryBar  ExitBar  EntryPrice  Exit...  \n",
       "4       Size  EntryBar  ExitBar  EntryPrice   Exi...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_colwidth', None)  # Show full width of each column\n",
    "\n",
    "rdf = pd.DataFrame(df_list)\n",
    "random_rdf = pd.DataFrame(random_df_list)\n",
    "\n",
    "display(random_rdf.head())\n",
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     30.000000\n",
       "mean     232.300000\n",
       "std       89.463208\n",
       "min       66.000000\n",
       "25%      181.500000\n",
       "50%      250.500000\n",
       "75%      298.750000\n",
       "max      357.000000\n",
       "Name: # Trades, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf['# Trades'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# actual = rdf['actual_ls'][0]\n",
    "# predicted = rdf['predicted_ls'][0]\n",
    "\n",
    "# cm = confusion_matrix(actual, predicted)\n",
    "# print(f\"Confusion matrix:\\n{cm}\")\n",
    "\n",
    "# # Extracting TP, TN, FP, FN\n",
    "# # First row is actually negative, second row is actually positive\n",
    "# TP = cm[1, 1]\n",
    "# TN = cm[0, 0]\n",
    "# FP = cm[0, 1]\n",
    "# FN = cm[1, 0]\n",
    "\n",
    "# accuracy = accuracy_score(actual, predicted)\n",
    "# precision = precision_score(actual, predicted)\n",
    "# recall = recall_score(actual, predicted)\n",
    "# f1 = f1_score(actual, predicted)\n",
    "\n",
    "# print(f\"Accuracy: {accuracy:.2f}\")\n",
    "# print(f\"Precision: {precision:.2f}\")\n",
    "# print(f\"Recall: {recall:.2f}\")\n",
    "# print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Append each dictionary as rows into a new df\n",
    "# Temporarily adjust display settings to show the full content of one row\n",
    "def calc_f1(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp = df.copy(deep=True)\n",
    "    tmp['f1_score'] = np.nan\n",
    "    # Iterate through each row in rdf\n",
    "    for idx, row in tmp.iterrows():\n",
    "        actual = row['actual_ls']\n",
    "        predicted = row['predicted_ls']\n",
    "        \n",
    "        tmp.at[idx, 'f1_score'] = f1_score(actual, predicted, zero_division=0)\n",
    "    return tmp\n",
    "\n",
    "def cacl_sharpe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp = df.copy(deep=True)\n",
    "    # ADJ_INTEREST_RATE_NOV = 4.42 / 100 / BACKTEST_FREQUENCY_ANN # Assume the yield is annualised\n",
    "    ADJ_INTEREST_RATE_NOV = (1 + 4.42 / 100) ** (1 / BACKTEST_FREQUENCY_ANN) - 1\n",
    "    # print(ADJ_INTEREST_RATE_NOV)\n",
    "    # More complicated than this because the portfolio uses varying fractions of the liquidity pool to invest\n",
    "    # rdf['ReturnPctList'].apply(lambda returns: np.prod([(1 + r) for r in returns]) - 1)\n",
    "    tmp['ExcessReturn'] = tmp['ReturnPctList'].apply(lambda returnsPct: (pd.Series(returnsPct) - ADJ_INTEREST_RATE_NOV).tolist())\n",
    "    tmp['ExcessReturnMean'] = tmp['ExcessReturn'].apply(lambda excess_returns: np.mean(excess_returns))\n",
    "    tmp['ExcessReturnStdDev'] = tmp['ExcessReturn'].apply(lambda excess_returns: np.std(excess_returns))\n",
    "    tmp['AdjSharpeRatio'] = tmp['ExcessReturnMean'] / tmp['ExcessReturnStdDev'] * np.sqrt(BACKTEST_FREQUENCY_ANN)\n",
    "\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    tmp = df.copy(deep=True)\n",
    "    # Positions (positive for long, negative for short) * (diff in exit and entry price) is the profit and loss for each trade\n",
    "    tmp['pl_list'] = tmp['_trades'].apply(lambda df: (df['Size'] * (df['ExitPrice'] - df['EntryPrice'])).tolist())\n",
    "    # print(len(rdf['pl_list'][0]))\n",
    "\n",
    "    # In general if the prediction is neutral it won't trade\n",
    "    # The actual up or down depends on the entry and exit price\n",
    "    tmp['actual_ls'] = tmp['_trades'].apply(lambda df: ((df['ExitPrice'] - df['EntryPrice'] >=0).astype(int)).tolist())\n",
    "    # The predicted up or down depends on my position size (vector)\n",
    "    tmp['predicted_ls'] = tmp['_trades'].apply(lambda df: ((df['Size'] >= 0).astype(int)).tolist())\n",
    "\n",
    "\n",
    "    # The ReturnPct in the backtesting framework does not account for the size\n",
    "    for idx, row in rdf.iterrows():\n",
    "        df = row['_trades']\n",
    "        df['ReturnPct'] = df['PnL'] / df['EntryPrice']\n",
    "        rdf.at[idx, '_trades'] = df\n",
    "\n",
    "    tmp['ReturnPctList'] = tmp['_trades'].apply(lambda df: df['ReturnPct'].tolist())\n",
    "\n",
    "    # F1 score\n",
    "    tmp = calc_f1(tmp)\n",
    "\n",
    "    # Sharpe ratio\n",
    "    tmp = cacl_sharpe(tmp)\n",
    "\n",
    "    # Annualised return\n",
    "    tmp['annualised_return'] = tmp['Return [%]'] * BACKTEST_FREQUENCY_ANN\n",
    "    return tmp\n",
    "# # Check that the sum of profit and loss is equal to the diff between equity final - start (no comms)\n",
    "# print(rdf['pl_list'].apply(lambda aList: np.sum(aList)) - (rdf['Equity Final [$]'] - pd.Series([equity_start] * len(rdf))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Exposure Time [%]</th>\n",
       "      <th>Equity Final [$]</th>\n",
       "      <th>Equity Peak [$]</th>\n",
       "      <th>Return [%]</th>\n",
       "      <th>Buy &amp; Hold Return [%]</th>\n",
       "      <th>Return (Ann.) [%]</th>\n",
       "      <th>Volatility (Ann.) [%]</th>\n",
       "      <th>...</th>\n",
       "      <th>pl_list</th>\n",
       "      <th>actual_ls</th>\n",
       "      <th>predicted_ls</th>\n",
       "      <th>ReturnPctList</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>ExcessReturn</th>\n",
       "      <th>ExcessReturnMean</th>\n",
       "      <th>ExcessReturnStdDev</th>\n",
       "      <th>AdjSharpeRatio</th>\n",
       "      <th>annualised_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31.460603</td>\n",
       "      <td>10193.186035</td>\n",
       "      <td>10670.183444</td>\n",
       "      <td>1.931860</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[50.95999999999984, 100.87999999999988, 98.061...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[0.020792446825438793, 0.02057591345388987, 0....</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>[0.00992101716420013, 0.009704483792651208, 0....</td>\n",
       "      <td>-0.009974</td>\n",
       "      <td>0.011644</td>\n",
       "      <td>-1.713145</td>\n",
       "      <td>7.727441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>44.598382</td>\n",
       "      <td>9860.523833</td>\n",
       "      <td>10095.196224</td>\n",
       "      <td>-1.394762</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-28.582840000000317, -31.336500000000456, -30...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>[-0.005790571503818898, -0.006467134454648749,...</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>[-0.01666200116505756, -0.01733856411588741, -...</td>\n",
       "      <td>-0.011453</td>\n",
       "      <td>0.017412</td>\n",
       "      <td>-1.315590</td>\n",
       "      <td>-5.579047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>49.824830</td>\n",
       "      <td>10255.372933</td>\n",
       "      <td>10559.846397</td>\n",
       "      <td>2.553729</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-30.326659999999606, -29.38286000000005, -14....</td>\n",
       "      <td>[0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, ...</td>\n",
       "      <td>[-0.006130610743193432, -0.00597372872396662, ...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>[-0.017002040404432095, -0.016845158385205283,...</td>\n",
       "      <td>-0.009575</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>-1.596081</td>\n",
       "      <td>10.214917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>66.931015</td>\n",
       "      <td>10274.145036</td>\n",
       "      <td>10976.816530</td>\n",
       "      <td>2.741450</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-7.10904000000005, -4.5639999999999645, -14.7...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>[-0.006262698874147765, -0.006053371531646201,...</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>[-0.017134128535386428, -0.016924801192884864,...</td>\n",
       "      <td>-0.010532</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>-1.812612</td>\n",
       "      <td>10.965801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>61.621759</td>\n",
       "      <td>9182.876018</td>\n",
       "      <td>10013.517400</td>\n",
       "      <td>-8.171240</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-28.132910000000493, -24.32000000000002, 52.2...</td>\n",
       "      <td>[0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-0.005724444119964089, -0.006764612620230315,...</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>[-0.016595873781202752, -0.017636042281468978,...</td>\n",
       "      <td>-0.011803</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>-2.203059</td>\n",
       "      <td>-32.684959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>67.083891</td>\n",
       "      <td>9536.888398</td>\n",
       "      <td>10845.070951</td>\n",
       "      <td>-4.631116</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-30.93999999999994, -28.822499999999707, -27....</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[-0.006275709313363631, -0.005999999999999894,...</td>\n",
       "      <td>0.281553</td>\n",
       "      <td>[-0.017147138974602294, -0.016871429661238557,...</td>\n",
       "      <td>-0.011843</td>\n",
       "      <td>0.015006</td>\n",
       "      <td>-1.578479</td>\n",
       "      <td>-18.524464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>73.300847</td>\n",
       "      <td>10728.298969</td>\n",
       "      <td>11069.304293</td>\n",
       "      <td>7.282990</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-7.741999999999962, -14.634016800000069, 94.6...</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[-0.00586659594218264, -0.0059237678261327975,...</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>[-0.016738025603421303, -0.01679519748737146, ...</td>\n",
       "      <td>-0.009720</td>\n",
       "      <td>0.013503</td>\n",
       "      <td>-1.439635</td>\n",
       "      <td>29.131959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>80.658004</td>\n",
       "      <td>10344.255609</td>\n",
       "      <td>10820.201918</td>\n",
       "      <td>3.442556</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-27.313519999999414, -11.464700000000022, -24...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[-0.005573050397877921, -0.004668607728957053,...</td>\n",
       "      <td>0.321918</td>\n",
       "      <td>[-0.016444480059116584, -0.015540037390195716,...</td>\n",
       "      <td>-0.009867</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>-1.657548</td>\n",
       "      <td>13.770224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>83.884324</td>\n",
       "      <td>10558.285757</td>\n",
       "      <td>11126.065950</td>\n",
       "      <td>5.582858</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-15.46999999999997, -3.974999999999966, 94.63...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[-0.0063039677914922265, -0.007004096735826470...</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>[-0.01717539745273089, -0.017875526397065133, ...</td>\n",
       "      <td>-0.009568</td>\n",
       "      <td>0.012805</td>\n",
       "      <td>-1.494484</td>\n",
       "      <td>22.331430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>85.820753</td>\n",
       "      <td>10944.334844</td>\n",
       "      <td>10961.040229</td>\n",
       "      <td>9.443348</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-29.941599999999312, -28.444000000000585, -37...</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, ...</td>\n",
       "      <td>[-0.006106692120054991, -0.0057895850973752605...</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>[-0.016978121781293654, -0.016661014758613923,...</td>\n",
       "      <td>-0.010331</td>\n",
       "      <td>0.014186</td>\n",
       "      <td>-1.456448</td>\n",
       "      <td>37.773394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>85.486337</td>\n",
       "      <td>9351.655053</td>\n",
       "      <td>10041.198526</td>\n",
       "      <td>-6.483449</td>\n",
       "      <td>6.905782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-29.421599999999785, -30.249960000000385, -3....</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>[-0.006000000000000005, -0.0061578278818673615...</td>\n",
       "      <td>0.321608</td>\n",
       "      <td>[-0.01687142966123867, -0.017029257543106024, ...</td>\n",
       "      <td>-0.010602</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>-1.668660</td>\n",
       "      <td>-25.933798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start      End  Duration  Exposure Time [%]  Equity Final [$]  \\\n",
       "0     0.0  31397.0   31397.0          31.460603      10193.186035   \n",
       "1     0.0  31397.0   31397.0          44.598382       9860.523833   \n",
       "2     0.0  31397.0   31397.0          49.824830      10255.372933   \n",
       "3     0.0  31397.0   31397.0          66.931015      10274.145036   \n",
       "4     0.0  31397.0   31397.0          61.621759       9182.876018   \n",
       "5     0.0  31397.0   31397.0          67.083891       9536.888398   \n",
       "6     0.0  31397.0   31397.0          73.300847      10728.298969   \n",
       "7     0.0  31397.0   31397.0          80.658004      10344.255609   \n",
       "8     0.0  31397.0   31397.0          83.884324      10558.285757   \n",
       "9     0.0  31397.0   31397.0          85.820753      10944.334844   \n",
       "10    0.0  31397.0   31397.0          85.486337       9351.655053   \n",
       "\n",
       "    Equity Peak [$]  Return [%]  Buy & Hold Return [%]  Return (Ann.) [%]  \\\n",
       "0      10670.183444    1.931860               6.905782                0.0   \n",
       "1      10095.196224   -1.394762               6.905782                0.0   \n",
       "2      10559.846397    2.553729               6.905782                0.0   \n",
       "3      10976.816530    2.741450               6.905782                0.0   \n",
       "4      10013.517400   -8.171240               6.905782                0.0   \n",
       "5      10845.070951   -4.631116               6.905782                0.0   \n",
       "6      11069.304293    7.282990               6.905782                0.0   \n",
       "7      10820.201918    3.442556               6.905782                0.0   \n",
       "8      11126.065950    5.582858               6.905782                0.0   \n",
       "9      10961.040229    9.443348               6.905782                0.0   \n",
       "10     10041.198526   -6.483449               6.905782                0.0   \n",
       "\n",
       "    Volatility (Ann.) [%]  ...  \\\n",
       "0                     NaN  ...   \n",
       "1                     NaN  ...   \n",
       "2                     NaN  ...   \n",
       "3                     NaN  ...   \n",
       "4                     NaN  ...   \n",
       "5                     NaN  ...   \n",
       "6                     NaN  ...   \n",
       "7                     NaN  ...   \n",
       "8                     NaN  ...   \n",
       "9                     NaN  ...   \n",
       "10                    NaN  ...   \n",
       "\n",
       "                                              pl_list  \\\n",
       "0   [50.95999999999984, 100.87999999999988, 98.061...   \n",
       "1   [-28.582840000000317, -31.336500000000456, -30...   \n",
       "2   [-30.326659999999606, -29.38286000000005, -14....   \n",
       "3   [-7.10904000000005, -4.5639999999999645, -14.7...   \n",
       "4   [-28.132910000000493, -24.32000000000002, 52.2...   \n",
       "5   [-30.93999999999994, -28.822499999999707, -27....   \n",
       "6   [-7.741999999999962, -14.634016800000069, 94.6...   \n",
       "7   [-27.313519999999414, -11.464700000000022, -24...   \n",
       "8   [-15.46999999999997, -3.974999999999966, 94.63...   \n",
       "9   [-29.941599999999312, -28.444000000000585, -37...   \n",
       "10  [-29.421599999999785, -30.249960000000385, -3....   \n",
       "\n",
       "                                            actual_ls  \\\n",
       "0   [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, ...   \n",
       "1   [0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, ...   \n",
       "2   [0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, ...   \n",
       "3   [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "4   [0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, ...   \n",
       "5   [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
       "6   [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "7   [1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, ...   \n",
       "8   [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9   [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...   \n",
       "10  [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                         predicted_ls  \\\n",
       "0   [1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, ...   \n",
       "1   [1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, ...   \n",
       "2   [1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, ...   \n",
       "3   [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, ...   \n",
       "4   [1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, ...   \n",
       "5   [0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, ...   \n",
       "6   [0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, ...   \n",
       "7   [0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, ...   \n",
       "8   [0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "9   [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, ...   \n",
       "10  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, ...   \n",
       "\n",
       "                                        ReturnPctList  f1_score  \\\n",
       "0   [0.020792446825438793, 0.02057591345388987, 0....  0.327869   \n",
       "1   [-0.005790571503818898, -0.006467134454648749,...  0.224490   \n",
       "2   [-0.006130610743193432, -0.00597372872396662, ...  0.272727   \n",
       "3   [-0.006262698874147765, -0.006053371531646201,...  0.326087   \n",
       "4   [-0.005724444119964089, -0.006764612620230315,...  0.255319   \n",
       "5   [-0.006275709313363631, -0.005999999999999894,...  0.281553   \n",
       "6   [-0.00586659594218264, -0.0059237678261327975,...  0.350000   \n",
       "7   [-0.005573050397877921, -0.004668607728957053,...  0.321918   \n",
       "8   [-0.0063039677914922265, -0.007004096735826470...  0.341176   \n",
       "9   [-0.006106692120054991, -0.0057895850973752605...  0.362069   \n",
       "10  [-0.006000000000000005, -0.0061578278818673615...  0.321608   \n",
       "\n",
       "                                         ExcessReturn  ExcessReturnMean  \\\n",
       "0   [0.00992101716420013, 0.009704483792651208, 0....         -0.009974   \n",
       "1   [-0.01666200116505756, -0.01733856411588741, -...         -0.011453   \n",
       "2   [-0.017002040404432095, -0.016845158385205283,...         -0.009575   \n",
       "3   [-0.017134128535386428, -0.016924801192884864,...         -0.010532   \n",
       "4   [-0.016595873781202752, -0.017636042281468978,...         -0.011803   \n",
       "5   [-0.017147138974602294, -0.016871429661238557,...         -0.011843   \n",
       "6   [-0.016738025603421303, -0.01679519748737146, ...         -0.009720   \n",
       "7   [-0.016444480059116584, -0.015540037390195716,...         -0.009867   \n",
       "8   [-0.01717539745273089, -0.017875526397065133, ...         -0.009568   \n",
       "9   [-0.016978121781293654, -0.016661014758613923,...         -0.010331   \n",
       "10  [-0.01687142966123867, -0.017029257543106024, ...         -0.010602   \n",
       "\n",
       "    ExcessReturnStdDev  AdjSharpeRatio  annualised_return  \n",
       "0             0.011644       -1.713145           7.727441  \n",
       "1             0.017412       -1.315590          -5.579047  \n",
       "2             0.011998       -1.596081          10.214917  \n",
       "3             0.011621       -1.812612          10.965801  \n",
       "4             0.010715       -2.203059         -32.684959  \n",
       "5             0.015006       -1.578479         -18.524464  \n",
       "6             0.013503       -1.439635          29.131959  \n",
       "7             0.011905       -1.657548          13.770224  \n",
       "8             0.012805       -1.494484          22.331430  \n",
       "9             0.014186       -1.456448          37.773394  \n",
       "10            0.012707       -1.668660         -25.933798  \n",
       "\n",
       "[11 rows x 41 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf2 = create_features(df=rdf)\n",
    "random_rdf2 = create_features(df=random_rdf)\n",
    "\n",
    "random_rdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stm_tech</th>\n",
       "      <th>lemma</th>\n",
       "      <th>content</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Exposure Time [%]</th>\n",
       "      <th>Equity Final [$]</th>\n",
       "      <th>Equity Peak [$]</th>\n",
       "      <th>Return [%]</th>\n",
       "      <th>...</th>\n",
       "      <th>pl_list</th>\n",
       "      <th>actual_ls</th>\n",
       "      <th>predicted_ls</th>\n",
       "      <th>ReturnPctList</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>ExcessReturn</th>\n",
       "      <th>ExcessReturnMean</th>\n",
       "      <th>ExcessReturnStdDev</th>\n",
       "      <th>AdjSharpeRatio</th>\n",
       "      <th>annualised_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blob</td>\n",
       "      <td>No</td>\n",
       "      <td>cln_smr</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>36.113765</td>\n",
       "      <td>10672.988005</td>\n",
       "      <td>11202.229936</td>\n",
       "      <td>6.72988</td>\n",
       "      <td>...</td>\n",
       "      <td>[49.869222000000036, 97.44800000000049, -38.84...</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.2606723224086563, 0.5089199916440386, -0.19...</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>[0.24980089274741762, 0.4980485619827999, -0.2...</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>0.218893</td>\n",
       "      <td>0.160188</td>\n",
       "      <td>26.91952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  stm_tech lemma  content  Start      End  Duration  Exposure Time [%]  \\\n",
       "7     blob    No  cln_smr    0.0  31397.0   31397.0          36.113765   \n",
       "\n",
       "   Equity Final [$]  Equity Peak [$]  Return [%]  ...  \\\n",
       "7      10672.988005     11202.229936     6.72988  ...   \n",
       "\n",
       "                                             pl_list  \\\n",
       "7  [49.869222000000036, 97.44800000000049, -38.84...   \n",
       "\n",
       "                                           actual_ls  \\\n",
       "7  [1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, ...   \n",
       "\n",
       "                                        predicted_ls  \\\n",
       "7  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                       ReturnPctList  f1_score  \\\n",
       "7  [0.2606723224086563, 0.5089199916440386, -0.19...  0.510638   \n",
       "\n",
       "                                        ExcessReturn  ExcessReturnMean  \\\n",
       "7  [0.24980089274741762, 0.4980485619827999, -0.2...          0.017532   \n",
       "\n",
       "   ExcessReturnStdDev  AdjSharpeRatio  annualised_return  \n",
       "7            0.218893        0.160188           26.91952  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf2[rdf2['f1_score'] > 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpe Ratio\n",
    "https://home.treasury.gov/resource-center/data-chart-center/interest-rates/TextView?type=daily_treasury_yield_curve&field_tdr_date_value=2023\n",
    "- On 2023-11-01, the rate of the 1 month T-bill is 4.42% p.a.\n",
    "- Scaling sharpe ratio: Scale the mean excess returns by the frequency, scale the standard deviation by the square root of frequency,\n",
    "hence you get freq / sqrt(freq) = sqrt(freq)\n",
    "- For using compound interest rate to find the monthly rate, need to use a fractional power, instead of discounting (negative exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sharpe ratio greater than thresh: 0\n",
      "0.20425817295049517\n"
     ]
    }
   ],
   "source": [
    "thresh = 1.0\n",
    "print(f\"Number of sharpe ratio greater than thresh: {np.sum(rdf2['AdjSharpeRatio'] > thresh)}\")\n",
    "print(np.max(rdf2['AdjSharpeRatio']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7696867160000185\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(rdf['Return [%]']))\n",
    "\n",
    "print(len(rdf[rdf['Win Rate [%]'] > 50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stm_tech</th>\n",
       "      <th>lemma</th>\n",
       "      <th>content</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Exposure Time [%]</th>\n",
       "      <th>Equity Final [$]</th>\n",
       "      <th>Equity Peak [$]</th>\n",
       "      <th>Return [%]</th>\n",
       "      <th>...</th>\n",
       "      <th>pl_list</th>\n",
       "      <th>actual_ls</th>\n",
       "      <th>predicted_ls</th>\n",
       "      <th>ReturnPctList</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>ExcessReturn</th>\n",
       "      <th>ExcessReturnMean</th>\n",
       "      <th>ExcessReturnStdDev</th>\n",
       "      <th>AdjSharpeRatio</th>\n",
       "      <th>annualised_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>stc</td>\n",
       "      <td>No</td>\n",
       "      <td>cln_hdl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[-14.081391999999852, -9.720000000000027, -15....</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, ...</td>\n",
       "      <td>[-0.07432378638035053, -0.05146124523507003, -...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.0851952160415892, -0.06233267489630869, -0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>62.077627</td>\n",
       "      <td>10776.968672</td>\n",
       "      <td>11188.694023</td>\n",
       "      <td>7.769687</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.351614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.180473</td>\n",
       "      <td>0.031470</td>\n",
       "      <td>31.078747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.012658</td>\n",
       "      <td>490.157994</td>\n",
       "      <td>437.839947</td>\n",
       "      <td>4.901580</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>0.018547</td>\n",
       "      <td>0.111188</td>\n",
       "      <td>19.606320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>28.473151</td>\n",
       "      <td>9764.202526</td>\n",
       "      <td>10483.545670</td>\n",
       "      <td>-2.357975</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.024931</td>\n",
       "      <td>0.155202</td>\n",
       "      <td>-0.248639</td>\n",
       "      <td>-9.431899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>61.253902</td>\n",
       "      <td>10587.680763</td>\n",
       "      <td>10790.249869</td>\n",
       "      <td>5.876808</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.289039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.163816</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>23.507231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>69.504427</td>\n",
       "      <td>10741.675323</td>\n",
       "      <td>11168.262196</td>\n",
       "      <td>7.416753</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.348055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.179950</td>\n",
       "      <td>0.034169</td>\n",
       "      <td>29.667013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>72.955284</td>\n",
       "      <td>10972.672271</td>\n",
       "      <td>11517.021581</td>\n",
       "      <td>9.726723</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009829</td>\n",
       "      <td>0.191426</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>38.906891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>31397.0</td>\n",
       "      <td>75.778712</td>\n",
       "      <td>11794.776317</td>\n",
       "      <td>12120.597150</td>\n",
       "      <td>17.947763</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018483</td>\n",
       "      <td>0.220731</td>\n",
       "      <td>0.204258</td>\n",
       "      <td>71.791053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stm_tech lemma  content  Start      End  Duration  Exposure Time [%]  \\\n",
       "count        30    30       30   30.0     30.0      30.0          30.000000   \n",
       "unique        5     2        3    NaN      NaN       NaN                NaN   \n",
       "top         stc    No  cln_hdl    NaN      NaN       NaN                NaN   \n",
       "freq          6    15       10    NaN      NaN       NaN                NaN   \n",
       "mean        NaN   NaN      NaN    0.0  31397.0   31397.0          62.077627   \n",
       "std         NaN   NaN      NaN    0.0      0.0       0.0          16.012658   \n",
       "min         NaN   NaN      NaN    0.0  31397.0   31397.0          28.473151   \n",
       "25%         NaN   NaN      NaN    0.0  31397.0   31397.0          61.253902   \n",
       "50%         NaN   NaN      NaN    0.0  31397.0   31397.0          69.504427   \n",
       "75%         NaN   NaN      NaN    0.0  31397.0   31397.0          72.955284   \n",
       "max         NaN   NaN      NaN    0.0  31397.0   31397.0          75.778712   \n",
       "\n",
       "        Equity Final [$]  Equity Peak [$]  Return [%]  ...  \\\n",
       "count          30.000000        30.000000   30.000000  ...   \n",
       "unique               NaN              NaN         NaN  ...   \n",
       "top                  NaN              NaN         NaN  ...   \n",
       "freq                 NaN              NaN         NaN  ...   \n",
       "mean        10776.968672     11188.694023    7.769687  ...   \n",
       "std           490.157994       437.839947    4.901580  ...   \n",
       "min          9764.202526     10483.545670   -2.357975  ...   \n",
       "25%         10587.680763     10790.249869    5.876808  ...   \n",
       "50%         10741.675323     11168.262196    7.416753  ...   \n",
       "75%         10972.672271     11517.021581    9.726723  ...   \n",
       "max         11794.776317     12120.597150   17.947763  ...   \n",
       "\n",
       "                                                  pl_list  \\\n",
       "count                                                  30   \n",
       "unique                                                 30   \n",
       "top     [-14.081391999999852, -9.720000000000027, -15....   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                actual_ls  \\\n",
       "count                                                  30   \n",
       "unique                                                 30   \n",
       "top     [0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, ...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                             predicted_ls  \\\n",
       "count                                                  30   \n",
       "unique                                                 30   \n",
       "top     [1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, ...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                            ReturnPctList   f1_score  \\\n",
       "count                                                  30  30.000000   \n",
       "unique                                                 30        NaN   \n",
       "top     [-0.07432378638035053, -0.05146124523507003, -...        NaN   \n",
       "freq                                                    1        NaN   \n",
       "mean                                                  NaN   0.351614   \n",
       "std                                                   NaN   0.084003   \n",
       "min                                                   NaN   0.191304   \n",
       "25%                                                   NaN   0.289039   \n",
       "50%                                                   NaN   0.348055   \n",
       "75%                                                   NaN   0.420504   \n",
       "max                                                   NaN   0.510638   \n",
       "\n",
       "                                             ExcessReturn  ExcessReturnMean  \\\n",
       "count                                                  30         30.000000   \n",
       "unique                                                 30               NaN   \n",
       "top     [-0.0851952160415892, -0.06233267489630869, -0...               NaN   \n",
       "freq                                                    1               NaN   \n",
       "mean                                                  NaN          0.002761   \n",
       "std                                                   NaN          0.010841   \n",
       "min                                                   NaN         -0.024931   \n",
       "25%                                                   NaN         -0.000056   \n",
       "50%                                                   NaN          0.002814   \n",
       "75%                                                   NaN          0.009829   \n",
       "max                                                   NaN          0.018483   \n",
       "\n",
       "        ExcessReturnStdDev  AdjSharpeRatio  annualised_return  \n",
       "count            30.000000       30.000000          30.000000  \n",
       "unique                 NaN             NaN                NaN  \n",
       "top                    NaN             NaN                NaN  \n",
       "freq                   NaN             NaN                NaN  \n",
       "mean              0.180473        0.031470          31.078747  \n",
       "std               0.018547        0.111188          19.606320  \n",
       "min               0.155202       -0.248639          -9.431899  \n",
       "25%               0.163816       -0.000656          23.507231  \n",
       "50%               0.179950        0.034169          29.667013  \n",
       "75%               0.191426        0.097503          38.906891  \n",
       "max               0.220731        0.204258          71.791053  \n",
       "\n",
       "[11 rows x 44 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf2.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', None)  # Show all columns\n",
    "# pd.set_option('display.max_colwidth', None)  # Show full width of each column\n",
    "\n",
    "rdf_bottom = rdf2.sort_values(by='Return [%]', ascending=True).head()\n",
    "rdf_top = rdf2.sort_values(by='Return [%]', ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann-Whitney U Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 6 Statistically greater!\n",
      "12 8 Statistically greater!\n",
      "12 9 Statistically greater!\n",
      "12 11 Statistically greater!\n",
      "13 6 Statistically greater!\n",
      "13 8 Statistically greater!\n",
      "13 9 Statistically greater!\n",
      "13 11 Statistically greater!\n",
      "14 6 Statistically greater!\n",
      "14 8 Statistically greater!\n",
      "14 9 Statistically greater!\n",
      "14 11 Statistically greater!\n",
      "15 6 Statistically greater!\n",
      "15 8 Statistically greater!\n",
      "15 9 Statistically greater!\n",
      "15 11 Statistically greater!\n",
      "16 6 Statistically greater!\n",
      "16 8 Statistically greater!\n",
      "16 9 Statistically greater!\n",
      "16 11 Statistically greater!\n",
      "17 6 Statistically greater!\n",
      "17 8 Statistically greater!\n",
      "17 9 Statistically greater!\n",
      "17 11 Statistically greater!\n",
      "18 6 Statistically greater!\n",
      "18 8 Statistically greater!\n",
      "18 9 Statistically greater!\n",
      "18 10 Statistically greater!\n",
      "18 11 Statistically greater!\n",
      "19 6 Statistically greater!\n",
      "19 7 Statistically greater!\n",
      "19 8 Statistically greater!\n",
      "19 9 Statistically greater!\n",
      "19 10 Statistically greater!\n",
      "19 11 Statistically greater!\n",
      "20 6 Statistically greater!\n",
      "20 8 Statistically greater!\n",
      "20 9 Statistically greater!\n",
      "20 11 Statistically greater!\n",
      "21 6 Statistically greater!\n",
      "21 8 Statistically greater!\n",
      "21 9 Statistically greater!\n",
      "21 10 Statistically greater!\n",
      "21 11 Statistically greater!\n",
      "22 6 Statistically greater!\n",
      "22 7 Statistically greater!\n",
      "22 8 Statistically greater!\n",
      "22 9 Statistically greater!\n",
      "22 10 Statistically greater!\n",
      "22 11 Statistically greater!\n",
      "22 15 Statistically greater!\n",
      "23 6 Statistically greater!\n",
      "23 8 Statistically greater!\n",
      "23 9 Statistically greater!\n",
      "23 11 Statistically greater!\n",
      "24 6 Statistically greater!\n",
      "24 8 Statistically greater!\n",
      "24 9 Statistically greater!\n",
      "24 11 Statistically greater!\n",
      "25 6 Statistically greater!\n",
      "25 7 Statistically greater!\n",
      "25 8 Statistically greater!\n",
      "25 9 Statistically greater!\n",
      "25 10 Statistically greater!\n",
      "25 11 Statistically greater!\n",
      "25 12 Statistically greater!\n",
      "25 15 Statistically greater!\n",
      "26 6 Statistically greater!\n",
      "26 8 Statistically greater!\n",
      "26 9 Statistically greater!\n",
      "26 10 Statistically greater!\n",
      "26 11 Statistically greater!\n",
      "26 15 Statistically greater!\n",
      "27 6 Statistically greater!\n",
      "27 8 Statistically greater!\n",
      "27 9 Statistically greater!\n",
      "27 11 Statistically greater!\n",
      "28 6 Statistically greater!\n",
      "28 7 Statistically greater!\n",
      "28 8 Statistically greater!\n",
      "28 9 Statistically greater!\n",
      "28 10 Statistically greater!\n",
      "28 11 Statistically greater!\n",
      "28 15 Statistically greater!\n",
      "28 27 Statistically greater!\n",
      "29 6 Statistically greater!\n",
      "29 7 Statistically greater!\n",
      "29 8 Statistically greater!\n",
      "29 9 Statistically greater!\n",
      "29 10 Statistically greater!\n",
      "29 11 Statistically greater!\n",
      "29 15 Statistically greater!\n",
      "29 27 Statistically greater!\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Assuming rdf2 is your DataFrame and 'ReturnPctList' is the column with returns data\n",
    "N_SAMPLES = len(rdf2)\n",
    "N_RANDOM_SAMPLES = len(random_rdf2)\n",
    "P_VALUE_BENCHMARK = 0.05\n",
    "matrix = np.zeros((N_SAMPLES, N_SAMPLES), dtype=int)\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "    for j in range(i):  # Lower triangular part\n",
    "        group_i = rdf2.loc[i, 'ReturnPctList']\n",
    "        group_j = rdf2.loc[j, 'ReturnPctList']\n",
    "        stat, p_value = mannwhitneyu(group_i, group_j, alternative='greater')\n",
    "        if p_value < P_VALUE_BENCHMARK:\n",
    "            matrix[i, j] = 1  # Mark as 1 if group_i is statistically greater than group_j\n",
    "            print(i, j, \"Statistically greater!\")\n",
    "# Sum across rows to find the \"best\" one\n",
    "row_sums = matrix.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{| c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c |}\n",
      "\\hline\n",
      " & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & 21 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 29 & Sum \\\\\n",
      "\\hline\n",
      "0 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "2 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "3 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "4 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "5 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "6 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "7 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "8 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "9 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "10 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "11 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 0 \\\\\n",
      "\\hline\n",
      "12 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "13 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "14 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "15 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "16 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "17 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "18 &   &   &   &   &   &   & 1 &   & 1 & 1 & 1 & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 5 \\\\\n",
      "\\hline\n",
      "19 &   &   &   &   &   &   & 1 & 1 & 1 & 1 & 1 & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 6 \\\\\n",
      "\\hline\n",
      "20 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "21 &   &   &   &   &   &   & 1 &   & 1 & 1 & 1 & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 5 \\\\\n",
      "\\hline\n",
      "22 &   &   &   &   &   &   & 1 & 1 & 1 & 1 & 1 & 1 &   &   &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 7 \\\\\n",
      "\\hline\n",
      "23 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "24 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "25 &   &   &   &   &   &   & 1 & 1 & 1 & 1 & 1 & 1 & 1 &   &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 8 \\\\\n",
      "\\hline\n",
      "26 &   &   &   &   &   &   & 1 &   & 1 & 1 & 1 & 1 &   &   &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 6 \\\\\n",
      "\\hline\n",
      "27 &   &   &   &   &   &   & 1 &   & 1 & 1 &   & 1 &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   &   & 4 \\\\\n",
      "\\hline\n",
      "28 &   &   &   &   &   &   & 1 & 1 & 1 & 1 & 1 & 1 &   &   &   & 1 &   &   &   &   &   &   &   &   &   &   &   & 1 &   &   & 8 \\\\\n",
      "\\hline\n",
      "29 &   &   &   &   &   &   & 1 & 1 & 1 & 1 & 1 & 1 &   &   &   & 1 &   &   &   &   &   &   &   &   &   &   &   & 1 &   &   & 8 \\\\\n",
      "\\hline\n",
      "\\end{tabular}%\n",
      "}\n",
      "\\caption{name}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def matrix_to_latex_with_indices(matrix, row_sums, name):\n",
    "    num_elements = matrix.shape[0]\n",
    "    latex_str = \"\\\\begin{table}[H]\\n\\\\centering\\n\"\n",
    "    latex_str += \"\\\\resizebox{\\\\textwidth}{!}{%\\n\"  # Resize table to fit within page width\n",
    "    latex_str += \"\\\\begin{tabular}{|\" + \" c |\" * (num_elements + 2) + \"}\\n\\\\hline\\n\"\n",
    "    \n",
    "    # Header row with indices\n",
    "    latex_str += \" & \" + \" & \".join(str(i) for i in range(num_elements)) + \" & Sum \\\\\\\\\\n\\\\hline\\n\"\n",
    "    \n",
    "    for i, row in enumerate(matrix):\n",
    "        # Row with index\n",
    "        row_str = str(i) + \" & \" + ' & '.join('1' if val == 1 else ' ' for val in row) + f\" & {row_sums[i]} \\\\\\\\\\n\\\\hline\\n\"\n",
    "        latex_str += row_str\n",
    "    latex_str += \"\\\\end{tabular}%\\n}\\n\"\n",
    "    latex_str += f\"\\\\caption{{name}}\\n\"\n",
    "    latex_str += \"\\\\end{table}\\n\"\n",
    "    return latex_str\n",
    "\n",
    "# Assuming 'matrix' is your numpy array and 'row_sums' is the sum across rows\n",
    "latex_table = matrix_to_latex_with_indices(matrix, row_sums, \"test\")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming rdf2 is your DataFrame and 'ReturnPctList' is the column with returns data\n",
    "matrix = np.zeros((N_SAMPLES, N_RANDOM_SAMPLES), dtype=int)\n",
    "\n",
    "for i in range(N_SAMPLES):\n",
    "    for j in range(N_RANDOM_SAMPLES):  # Lower triangular part\n",
    "        group_i = rdf2.loc[i, 'ReturnPctList']\n",
    "        group_j = random_rdf2.loc[j, 'ReturnPctList']\n",
    "        stat, p_value = mannwhitneyu(group_i, group_j, alternative='greater')\n",
    "        print(p_value)\n",
    "        if p_value < P_VALUE_BENCHMARK:\n",
    "            matrix[i, j] = 1  # Mark as 1 if group_i is statistically greater than group_j\n",
    "            print(i, j, \"Statistically greater!\")\n",
    "# Sum across rows to find the \"best\" one\n",
    "row_sums = matrix.sum(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = matrix_to_latex_with_indices(matrix, row_sums)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf2[:5].describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hist(df):\n",
    "    for i in range(len(df)):\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.hist(x=df.loc[i, 'ReturnPctList'], bins=10)\n",
    "        plt.figure(figsize=(5, 3))\n",
    "        plt.boxplot(x=df.loc[i, 'ReturnPctList'])\n",
    "# TODO: Include title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_hist(rdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = list(itertools.combinations(range(0, N_SAMPLES), 2))\n",
    "count = 0\n",
    "for i, j in combos:\n",
    "    ks_stat, ks_p_val = stats.ks_2samp(rdf2.ReturnPctList[i], rdf2.ReturnPctList[j])\n",
    "    # ks_stat, p_val = stats.ks_2samp(random_rdf2.ReturnPctList[i], random_rdf2.ReturnPctList[j])\n",
    "    \n",
    "    # Different distributions\n",
    "    if ks_p_val < P_VALUE_BENCHMARK:\n",
    "        count += 1\n",
    "print(f\"Number of pairs with different distributions: {count} / {len(combos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return1 = rdf2.ReturnPctList[0]\n",
    "return2 = random_rdf2.ReturnPctList[5]\n",
    "n_samples = len(rdf2)\n",
    "count = 0\n",
    "ttl_count = 0\n",
    "for i in range(N_SAMPLES):\n",
    "    for j in range(N_RANDOM_SAMPLES):\n",
    "        ks_stat, ks_p_val = stats.ks_2samp(rdf2.ReturnPctList[i], random_rdf2.ReturnPctList[j])\n",
    "        # ks_stat, p_val = stats.ks_2samp(random_rdf2.ReturnPctList[i], random_rdf2.ReturnPctList[j])\n",
    "        \n",
    "        # Different distributions\n",
    "        if ks_p_val < P_VALUE_BENCHMARK:\n",
    "            count += 1\n",
    "        ttl_count += 1\n",
    "print(f\"Number of pairs with different distributions: {count} / {ttl_count}\")\n",
    "\n",
    "# All the distributions of the samples are different from the random samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf2.columns\n",
    "\n",
    "def present(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp = df.copy(deep=True)\n",
    "    present_cols = [ \n",
    "        'Return [%]', 'annualised_return', '# Trades', 'Win Rate [%]',\n",
    "        'f1_score', 'AdjSharpeRatio']\n",
    "    \n",
    "    if 'stm_tech' in tmp.columns:\n",
    "        present_cols = ['stm_tech', 'lemma', 'content'] + present_cols\n",
    "    tmp = tmp[present_cols]\n",
    "    # , 'Best Trade [%]', 'Worst Trade [%]', 'Avg. Trade [%]'\n",
    "    # 'Max. Trade Duration', 'Avg. Trade Duration', 'Profit Factor',\n",
    "    # 'Expectancy [%]', 'SQN', 'Kelly Criterion',\n",
    "    # 'Avg. Drawdown [%]', 'Max. Drawdown Duration', 'Avg. Drawdown Duration'\n",
    "\n",
    "    stm_tech_dict = {\n",
    "        'stc': \"Sentic API\",\n",
    "        'blob': \"BlobText\",\n",
    "        'sid': \"VADER\",\n",
    "        'bert': \"BERT\",\n",
    "        'finbert': \"FinBERT\"\n",
    "    }\n",
    "\n",
    "    content_dict = {\n",
    "        'cln_hdl': 'Headline',\n",
    "        'cln_smr': 'Summary',\n",
    "        'cln_news': 'Content'\n",
    "    }\n",
    "    if 'stm_tech' in tmp.columns:\n",
    "        tmp['stm_tech'] = tmp['stm_tech'].apply(lambda name: stm_tech_dict.get(name, None))\n",
    "        tmp['content'] = tmp['content'].apply(lambda name: content_dict.get(name, None))\n",
    "    \n",
    "    for col in ['Return [%]', 'annualised_return', 'Win Rate [%]',\n",
    "                'f1_score', 'AdjSharpeRatio']:\n",
    "        tmp[col] = tmp[col].apply(lambda num: round(num, 2))\n",
    "\n",
    "    tmp['# Trades'] = tmp['# Trades'].apply(lambda num: round(num))\n",
    "    rename_dict = {\n",
    "        'stm_tech': 'Model',\n",
    "        'lemma': 'Lemma',\n",
    "        'content': 'Text',\n",
    "        'annualised_return': 'Ann. Return [%]',\n",
    "        'f1_score': 'F1 Score',\n",
    "        'AdjSharpeRatio': 'Sharpe Ratio',\n",
    "    }\n",
    "    tmp = tmp.rename(columns=rename_dict)\n",
    "    return tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf3 = present(rdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Model</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>VADER</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>VADER</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>VADER</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>VADER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>VADER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>VADER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>BERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>BERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>BERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>BERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>BERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>BERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     C       Model Lemma      Text\n",
       "0    0  Sentic API    No  Headline\n",
       "1    1  Sentic API    No   Summary\n",
       "2    2  Sentic API    No   Content\n",
       "3    3  Sentic API   Yes  Headline\n",
       "4    4  Sentic API   Yes   Summary\n",
       "5    5  Sentic API   Yes   Content\n",
       "6    6    BlobText    No  Headline\n",
       "7    7    BlobText    No   Summary\n",
       "8    8    BlobText    No   Content\n",
       "9    9    BlobText   Yes  Headline\n",
       "10  10    BlobText   Yes   Summary\n",
       "11  11    BlobText   Yes   Content\n",
       "12  12       VADER    No  Headline\n",
       "13  13       VADER    No   Summary\n",
       "14  14       VADER    No   Content\n",
       "15  15       VADER   Yes  Headline\n",
       "16  16       VADER   Yes   Summary\n",
       "17  17       VADER   Yes   Content\n",
       "18  18        BERT    No  Headline\n",
       "19  19        BERT    No   Summary\n",
       "20  20        BERT    No   Content\n",
       "21  21        BERT   Yes  Headline\n",
       "22  22        BERT   Yes   Summary\n",
       "23  23        BERT   Yes   Content\n",
       "24  24     FinBERT    No  Headline\n",
       "25  25     FinBERT    No   Summary\n",
       "26  26     FinBERT    No   Content\n",
       "27  27     FinBERT   Yes  Headline\n",
       "28  28     FinBERT   Yes   Summary\n",
       "29  29     FinBERT   Yes   Content"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_cols = ['Model', 'Lemma', 'Text']\n",
    "\n",
    "rdf3.index.name = 'C'\n",
    "other_cols = rdf3.columns.difference(combo_cols)\n",
    "rdf4 = rdf3[combo_cols]\n",
    "rdf4.reset_index(drop=False, inplace=True)\n",
    "rdf5 = rdf3[other_cols]\n",
    "rdf5.reset_index(drop=False, inplace=True)\n",
    "rdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Model', 'Lemma', 'Text', 'Return [%]', 'Ann. Return [%]', '# Trades',\n",
       "       'Win Rate [%]', 'F1 Score', 'Sharpe Ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht!]\n",
      "\\caption{Combinations of Models, Lemmatisation, and News Text}\n",
      "\\label{tab:combinations-of-models-lemmatisation-news-text}\n",
      "\\begin{tabular}{rlll}\n",
      "\\toprule\n",
      "C & Model & Lemma & Text \\\\\n",
      "\\midrule\n",
      "0 & Sentic API & No & Headline \\\\\n",
      "1 & Sentic API & No & Summary \\\\\n",
      "2 & Sentic API & No & Content \\\\\n",
      "3 & Sentic API & Yes & Headline \\\\\n",
      "4 & Sentic API & Yes & Summary \\\\\n",
      "5 & Sentic API & Yes & Content \\\\\n",
      "6 & BlobText & No & Headline \\\\\n",
      "7 & BlobText & No & Summary \\\\\n",
      "8 & BlobText & No & Content \\\\\n",
      "9 & BlobText & Yes & Headline \\\\\n",
      "10 & BlobText & Yes & Summary \\\\\n",
      "11 & BlobText & Yes & Content \\\\\n",
      "12 & VADER & No & Headline \\\\\n",
      "13 & VADER & No & Summary \\\\\n",
      "14 & VADER & No & Content \\\\\n",
      "15 & VADER & Yes & Headline \\\\\n",
      "16 & VADER & Yes & Summary \\\\\n",
      "17 & VADER & Yes & Content \\\\\n",
      "18 & BERT & No & Headline \\\\\n",
      "19 & BERT & No & Summary \\\\\n",
      "20 & BERT & No & Content \\\\\n",
      "21 & BERT & Yes & Headline \\\\\n",
      "22 & BERT & Yes & Summary \\\\\n",
      "23 & BERT & Yes & Content \\\\\n",
      "24 & FinBERT & No & Headline \\\\\n",
      "25 & FinBERT & No & Summary \\\\\n",
      "26 & FinBERT & No & Content \\\\\n",
      "27 & FinBERT & Yes & Headline \\\\\n",
      "28 & FinBERT & Yes & Summary \\\\\n",
      "29 & FinBERT & Yes & Content \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_str4 = rdf4.to_latex(index=False, float_format=\"%.2f\", escape=True, header=True, longtable=False, caption=\"Combinations of Models, Lemmatisation, and News Text\", label=\"tab:combinations-of-models-lemmatisation-news-text\", position=\"ht!\")\n",
    "latex_str5 = rdf5.to_latex(index=False, float_format=\"%.2f\", escape=True, header=True, longtable=False, caption=\"Trading Strategy Performance\", label=\"tab:trading_strategy_performance\", position=\"ht!\")\n",
    "\n",
    "print(latex_str4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht!]\n",
      "\\caption{Trading Strategy Performance}\n",
      "\\label{tab:trading_strategy_performance}\n",
      "\\begin{tabular}{rrrrrrr}\n",
      "\\toprule\n",
      "R & Return [\\%] & Ann. Return [\\%] & \\# Trades & Win Rate [\\%] & F1 Score & Sharpe Ratio \\\\\n",
      "\\midrule\n",
      "0 & 1.93 & 7.73 & 56 & 26.79 & 0.33 & -1.71 \\\\\n",
      "1 & -1.39 & -5.58 & 103 & 26.21 & 0.22 & -1.32 \\\\\n",
      "2 & 2.55 & 10.21 & 113 & 29.20 & 0.27 & -1.60 \\\\\n",
      "3 & 2.74 & 10.97 & 167 & 25.75 & 0.33 & -1.81 \\\\\n",
      "4 & -8.17 & -32.68 & 176 & 20.45 & 0.26 & -2.20 \\\\\n",
      "5 & -4.63 & -18.52 & 196 & 24.49 & 0.28 & -1.58 \\\\\n",
      "6 & 7.28 & 29.13 & 218 & 28.44 & 0.35 & -1.44 \\\\\n",
      "7 & 3.44 & 13.77 & 275 & 28.00 & 0.32 & -1.66 \\\\\n",
      "8 & 5.58 & 22.33 & 321 & 30.22 & 0.34 & -1.49 \\\\\n",
      "9 & 9.44 & 37.77 & 313 & 29.07 & 0.36 & -1.46 \\\\\n",
      "10 & -6.48 & -25.93 & 369 & 26.83 & 0.32 & -1.67 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_rdf3 = present(random_rdf2)\n",
    "random_rdf3.reset_index(drop=False, names='R', inplace=True)\n",
    "\n",
    "latex_str3 = random_rdf3.to_latex(index=False, float_format=\"%.2f\", escape=True, header=True, longtable=False, caption=\"Trading Strategy Performance\", label=\"tab:trading_strategy_performance\", position=\"ht!\")\n",
    "print(latex_str3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>C</th>\n",
       "      <th>Model</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Text</th>\n",
       "      <th>Ann. Return [%]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "      <td>71.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "      <td>67.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "      <td>62.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "      <td>59.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>VADER</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "      <td>48.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>VADER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "      <td>47.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>BERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "      <td>42.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "      <td>39.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>BERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "      <td>36.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "      <td>35.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "      <td>35.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "      <td>32.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "      <td>31.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>VADER</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "      <td>31.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>VADER</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "      <td>29.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "      <td>29.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>BERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "      <td>28.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>BERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "      <td>27.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>No</td>\n",
       "      <td>Summary</td>\n",
       "      <td>26.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>VADER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "      <td>25.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentic API</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "      <td>24.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>VADER</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "      <td>23.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>BERT</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "      <td>23.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>BERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "      <td>22.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>FinBERT</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "      <td>22.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Summary</td>\n",
       "      <td>19.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Headline</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>No</td>\n",
       "      <td>Content</td>\n",
       "      <td>-1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>No</td>\n",
       "      <td>Headline</td>\n",
       "      <td>-6.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>BlobText</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Content</td>\n",
       "      <td>-9.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank   C       Model Lemma      Text  Ann. Return [%]\n",
       "0      1  25     FinBERT    No   Summary            71.79\n",
       "1      2  29     FinBERT   Yes   Content            67.37\n",
       "2      3  26     FinBERT    No   Content            62.55\n",
       "3      4  28     FinBERT   Yes   Summary            59.39\n",
       "4      5  13       VADER    No   Summary            48.55\n",
       "5      6  16       VADER   Yes   Summary            47.40\n",
       "6      7  19        BERT    No   Summary            42.81\n",
       "7      8   4  Sentic API   Yes   Summary            39.63\n",
       "8      9  21        BERT   Yes  Headline            36.73\n",
       "9     10  24     FinBERT    No  Headline            35.95\n",
       "10    11   2  Sentic API    No   Content            35.73\n",
       "11    12   1  Sentic API    No   Summary            32.07\n",
       "12    13   3  Sentic API   Yes  Headline            31.69\n",
       "13    14  12       VADER    No  Headline            31.58\n",
       "14    15  14       VADER    No   Content            29.78\n",
       "15    16   5  Sentic API   Yes   Content            29.56\n",
       "16    17  22        BERT   Yes   Summary            28.73\n",
       "17    18  18        BERT    No  Headline            27.88\n",
       "18    19   7    BlobText    No   Summary            26.92\n",
       "19    20  15       VADER   Yes  Headline            25.77\n",
       "20    21   0  Sentic API    No  Headline            24.92\n",
       "21    22  17       VADER   Yes   Content            23.52\n",
       "22    23  20        BERT    No   Content            23.50\n",
       "23    24  23        BERT   Yes   Content            22.95\n",
       "24    25  27     FinBERT   Yes  Headline            22.45\n",
       "25    26  10    BlobText   Yes   Summary            19.70\n",
       "26    27   9    BlobText   Yes  Headline             1.07\n",
       "27    28   8    BlobText    No   Content            -1.29\n",
       "28    29   6    BlobText    No  Headline            -6.90\n",
       "29    30  11    BlobText   Yes   Content            -9.43"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['Return [%]', 'Ann. Return [%]', 'Win Rate [%]', 'F1 Score', 'Sharpe Ratio']\n",
    "def rank_df(df, idx) -> pd.DataFrame:\n",
    "    top = df.sort_values(by=metrics[idx], ascending=False)\n",
    "    top.reset_index(drop=False, names='C', inplace=True)\n",
    "    top.reset_index(drop=False, names='Rank', inplace=True)\n",
    "    top['Rank'] += 1\n",
    "    top = top[['Rank', 'C', 'Model', 'Lemma', 'Text', metrics[idx]]]\n",
    "    return top\n",
    "top_return_rdf3 = rank_df(df=rdf3, idx=1)\n",
    "top_return_rdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht!]\n",
      "\\caption{Trading Strategy Performance Ranked by Annual Returns}\n",
      "\\label{tab:trading_strategy_performance_by_annual_returns}\n",
      "\\begin{tabular}{rrlllr}\n",
      "\\toprule\n",
      "Rank & C & Model & Lemma & Text & Ann. Return [\\%] \\\\\n",
      "\\midrule\n",
      "1 & 25 & FinBERT & No & Summary & 71.79 \\\\\n",
      "2 & 29 & FinBERT & Yes & Content & 67.37 \\\\\n",
      "3 & 26 & FinBERT & No & Content & 62.55 \\\\\n",
      "4 & 28 & FinBERT & Yes & Summary & 59.39 \\\\\n",
      "5 & 13 & VADER & No & Summary & 48.55 \\\\\n",
      "6 & 16 & VADER & Yes & Summary & 47.40 \\\\\n",
      "7 & 19 & BERT & No & Summary & 42.81 \\\\\n",
      "8 & 4 & Sentic API & Yes & Summary & 39.63 \\\\\n",
      "9 & 21 & BERT & Yes & Headline & 36.73 \\\\\n",
      "10 & 24 & FinBERT & No & Headline & 35.95 \\\\\n",
      "11 & 2 & Sentic API & No & Content & 35.73 \\\\\n",
      "12 & 1 & Sentic API & No & Summary & 32.07 \\\\\n",
      "13 & 3 & Sentic API & Yes & Headline & 31.69 \\\\\n",
      "14 & 12 & VADER & No & Headline & 31.58 \\\\\n",
      "15 & 14 & VADER & No & Content & 29.78 \\\\\n",
      "16 & 5 & Sentic API & Yes & Content & 29.56 \\\\\n",
      "17 & 22 & BERT & Yes & Summary & 28.73 \\\\\n",
      "18 & 18 & BERT & No & Headline & 27.88 \\\\\n",
      "19 & 7 & BlobText & No & Summary & 26.92 \\\\\n",
      "20 & 15 & VADER & Yes & Headline & 25.77 \\\\\n",
      "21 & 0 & Sentic API & No & Headline & 24.92 \\\\\n",
      "22 & 17 & VADER & Yes & Content & 23.52 \\\\\n",
      "23 & 20 & BERT & No & Content & 23.50 \\\\\n",
      "24 & 23 & BERT & Yes & Content & 22.95 \\\\\n",
      "25 & 27 & FinBERT & Yes & Headline & 22.45 \\\\\n",
      "26 & 10 & BlobText & Yes & Summary & 19.70 \\\\\n",
      "27 & 9 & BlobText & Yes & Headline & 1.07 \\\\\n",
      "28 & 8 & BlobText & No & Content & -1.29 \\\\\n",
      "29 & 6 & BlobText & No & Headline & -6.90 \\\\\n",
      "30 & 11 & BlobText & Yes & Content & -9.43 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "return_str = top_return_rdf3.to_latex(index=False, float_format=\"%.2f\", escape=True, header=True, longtable=False, \n",
    "                                      caption=\"Trading Strategy Performance Ranked by Annual Returns\", \n",
    "                                      label=\"tab:trading_strategy_performance_by_annual_returns\", position=\"ht!\")\n",
    "print(return_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht!]\n",
      "\\caption{Trading Strategy Performance Ranked by F1 Score}\n",
      "\\label{tab:trading_strategy_performance_by_F1_score}\n",
      "\\begin{tabular}{rrlllr}\n",
      "\\toprule\n",
      "Rank & C & Model & Lemma & Text & F1 Score \\\\\n",
      "\\midrule\n",
      "1 & 7 & BlobText & No & Summary & 0.51 \\\\\n",
      "2 & 10 & BlobText & Yes & Summary & 0.49 \\\\\n",
      "3 & 2 & Sentic API & No & Content & 0.46 \\\\\n",
      "4 & 5 & Sentic API & Yes & Content & 0.45 \\\\\n",
      "5 & 4 & Sentic API & Yes & Summary & 0.43 \\\\\n",
      "6 & 8 & BlobText & No & Content & 0.43 \\\\\n",
      "7 & 17 & VADER & Yes & Content & 0.42 \\\\\n",
      "8 & 14 & VADER & No & Content & 0.42 \\\\\n",
      "9 & 1 & Sentic API & No & Summary & 0.42 \\\\\n",
      "10 & 3 & Sentic API & Yes & Headline & 0.40 \\\\\n",
      "11 & 0 & Sentic API & No & Headline & 0.39 \\\\\n",
      "12 & 16 & VADER & Yes & Summary & 0.39 \\\\\n",
      "13 & 13 & VADER & No & Summary & 0.39 \\\\\n",
      "14 & 11 & BlobText & Yes & Content & 0.38 \\\\\n",
      "15 & 26 & FinBERT & No & Content & 0.35 \\\\\n",
      "16 & 9 & BlobText & Yes & Headline & 0.35 \\\\\n",
      "17 & 29 & FinBERT & Yes & Content & 0.34 \\\\\n",
      "18 & 25 & FinBERT & No & Summary & 0.33 \\\\\n",
      "19 & 6 & BlobText & No & Headline & 0.32 \\\\\n",
      "20 & 28 & FinBERT & Yes & Summary & 0.31 \\\\\n",
      "21 & 21 & BERT & Yes & Headline & 0.30 \\\\\n",
      "22 & 18 & BERT & No & Headline & 0.29 \\\\\n",
      "23 & 24 & FinBERT & No & Headline & 0.29 \\\\\n",
      "24 & 12 & VADER & No & Headline & 0.28 \\\\\n",
      "25 & 27 & FinBERT & Yes & Headline & 0.28 \\\\\n",
      "26 & 15 & VADER & Yes & Headline & 0.27 \\\\\n",
      "27 & 19 & BERT & No & Summary & 0.26 \\\\\n",
      "28 & 20 & BERT & No & Content & 0.23 \\\\\n",
      "29 & 22 & BERT & Yes & Summary & 0.20 \\\\\n",
      "30 & 23 & BERT & Yes & Content & 0.19 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = ['Return [%]', 'Ann. Return [%]', 'Win Rate [%]', 'F1 Score', 'Sharpe Ratio']\n",
    "top_f1_rdf3 = rank_df(df=rdf3, idx=3)\n",
    "f1_str = top_f1_rdf3.to_latex(index=False, float_format=\"%.2f\", escape=True, header=True, longtable=False, \n",
    "                                      caption=\"Trading Strategy Performance Ranked by F1 Score\", \n",
    "                                      label=\"tab:trading_strategy_performance_by_F1_score\", position=\"ht!\")\n",
    "print(f1_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht!]\n",
      "\\caption{Trading Strategy Performance Ranked by Sharpe Ratio}\n",
      "\\label{tab:trading_strategy_performance_by_sharpe}\n",
      "\\begin{tabular}{rrlllr}\n",
      "\\toprule\n",
      "Rank & C & Model & Lemma & Text & Sharpe Ratio \\\\\n",
      "\\midrule\n",
      "1 & 25 & FinBERT & No & Summary & 0.20 \\\\\n",
      "2 & 29 & FinBERT & Yes & Content & 0.19 \\\\\n",
      "3 & 26 & FinBERT & No & Content & 0.17 \\\\\n",
      "4 & 7 & BlobText & No & Summary & 0.16 \\\\\n",
      "5 & 28 & FinBERT & Yes & Summary & 0.15 \\\\\n",
      "6 & 13 & VADER & No & Summary & 0.14 \\\\\n",
      "7 & 16 & VADER & Yes & Summary & 0.14 \\\\\n",
      "8 & 10 & BlobText & Yes & Summary & 0.10 \\\\\n",
      "9 & 19 & BERT & No & Summary & 0.09 \\\\\n",
      "10 & 12 & VADER & No & Headline & 0.08 \\\\\n",
      "11 & 24 & FinBERT & No & Headline & 0.07 \\\\\n",
      "12 & 14 & VADER & No & Content & 0.05 \\\\\n",
      "13 & 21 & BERT & Yes & Headline & 0.04 \\\\\n",
      "14 & 15 & VADER & Yes & Headline & 0.04 \\\\\n",
      "15 & 4 & Sentic API & Yes & Summary & 0.04 \\\\\n",
      "16 & 2 & Sentic API & No & Content & 0.03 \\\\\n",
      "17 & 17 & VADER & Yes & Content & 0.02 \\\\\n",
      "18 & 27 & FinBERT & Yes & Headline & 0.02 \\\\\n",
      "19 & 20 & BERT & No & Content & 0.01 \\\\\n",
      "20 & 1 & Sentic API & No & Summary & 0.00 \\\\\n",
      "21 & 18 & BERT & No & Headline & -0.00 \\\\\n",
      "22 & 22 & BERT & Yes & Summary & 0.00 \\\\\n",
      "23 & 5 & Sentic API & Yes & Content & 0.00 \\\\\n",
      "24 & 3 & Sentic API & Yes & Headline & -0.01 \\\\\n",
      "25 & 23 & BERT & Yes & Content & -0.02 \\\\\n",
      "26 & 0 & Sentic API & No & Headline & -0.04 \\\\\n",
      "27 & 9 & BlobText & Yes & Headline & -0.12 \\\\\n",
      "28 & 8 & BlobText & No & Content & -0.13 \\\\\n",
      "29 & 11 & BlobText & Yes & Content & -0.24 \\\\\n",
      "30 & 6 & BlobText & No & Headline & -0.25 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = ['Return [%]', 'Ann. Return [%]', 'Win Rate [%]', 'F1 Score', 'Sharpe Ratio']\n",
    "top_sharpe_rdf3 = rank_df(df=rdf3, idx=4)\n",
    "sharpe_str = top_sharpe_rdf3.to_latex(index=False, float_format=\"%.2f\", escape=True, header=True, longtable=False, \n",
    "                                      caption=\"Trading Strategy Performance Ranked by Sharpe Ratio\", \n",
    "                                      label=\"tab:trading_strategy_performance_by_sharpe\", position=\"ht!\")\n",
    "print(sharpe_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Construction\n",
    "- We actually have quite a good number of \"returns\" based on different techniques.\n",
    "- We can utilise the backtest data to choose the techniques that will be used in the future to obtain\n",
    "the best risk-adjusted return.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA\n",
    "\n",
    "- Before removing outliers, 19 significantly different pairs of groups were found, observed p value is about 0.04\n",
    "- After removing, 15 were found, observed p value is about 0.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "def anova(*groups: typing.List, plot:bool=False) -> bool:\n",
    "    # Calculates n F-statistic between bootstrap samples and return the list\n",
    "    def bootstrap_f_stat(data_groups, n_bootstraps=1000):\n",
    "        bs_f_stat_list = []\n",
    "        # data_groups is all the groups that we want to compare\n",
    "        \n",
    "        for _ in range(n_bootstraps):\n",
    "            # Get a list of randomly chosen samples for each group length\n",
    "            # The length of each group might be different\n",
    "            resampled_groups = [np.random.choice(group, size=len(group), replace=True) for group in data_groups]\n",
    "\n",
    "            # Calculate the F-statistic for ith bootstrap\n",
    "            # Unzip the resampled_groups to be parameters\n",
    "            f_stat, p_val = f_oneway(*resampled_groups)\n",
    "            bs_f_stat_list.append(f_stat)\n",
    "\n",
    "        return bs_f_stat_list\n",
    "\n",
    "    # Calculate the observed F-statistic\n",
    "    obs_f_stat, obs_p_val = f_oneway(*groups)\n",
    "\n",
    "    # Bootstrap the F-statistic\n",
    "    bs_f_stat_list = bootstrap_f_stat(data_groups=groups)\n",
    "\n",
    "    if plot:\n",
    "        # Plotting the histogram of bootstrapped F-statistics\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(bs_f_stat_list, bins=30, color='skyblue', alpha=0.7, label='Bootstrapped F-statistics')\n",
    "\n",
    "        # Marking the observed F-statistic\n",
    "        plt.axvline(obs_f_stat, color='red', linestyle='dashed', linewidth=2, label=f'Observed F-statistic ({obs_f_stat:.4f})')\n",
    "\n",
    "        plt.title('Distribution of Bootstrapped F-statistics with Observed F-statistic')\n",
    "        plt.xlabel('F-statistic')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    alpha = 0.05\n",
    "\n",
    "    upper_quantile = np.quantile(bs_f_stat_list, 1 - alpha)\n",
    "\n",
    "    if obs_f_stat >= upper_quantile:\n",
    "        print(\"The difference between groups is statistically significant.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No significant difference between groups was found.\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combination of 2 numbers from 0 to 29\n",
    "# TODO: Change the numbers\n",
    "all_combo = list(itertools.combinations(range(0, 30), 2))\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx in all_combo:\n",
    "    # Select the 'adj_returns' for each index in idx, creating a list of pd.Series\n",
    "    # Each pd.Series contains the 'adj_returns' values for one of the selected indices\n",
    "    group_returns = [rdf2.loc[i, 'ReturnPctList'] for i in idx]\n",
    "\n",
    "    # Convert the list of returns into a format suitable for the anova function\n",
    "    # Assuming the anova function is designed to take multiple pd.Series as separate arguments\n",
    "    stat_diff = anova(*group_returns, plot=False)\n",
    "\n",
    "    if stat_diff: break\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print(count / len(all_combo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normality_test(data: np.ndarray, plot=False):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - data: a numpy array\n",
    "    \"\"\"\n",
    "    data3 = data\n",
    "    # data2 = np.log(data)\n",
    "    # pl2 = pl\n",
    "    # q1 = data2.quantile(0.25)\n",
    "    # q3 = data2.quantile(0.75)\n",
    "    # iqr = q3 - q1\n",
    "\n",
    "    # # Define outliers\n",
    "    # lower_bound = q1 - 1.5 * iqr\n",
    "    # upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    # data3 = data2[(data2 >= lower_bound) & (data2 <= upper_bound)]\n",
    "\n",
    "    # Normality Test\n",
    "    _, p_value_normality_group1 = stats.shapiro(data3)\n",
    "\n",
    "    print(f\"Normality Test P-Values: Group1={p_value_normality_group1}\")\n",
    "    if plot:\n",
    "        # Q-Q Plots for Visual Normality Check\n",
    "        plt.figure(figsize=(5,3))\n",
    "        sm.qqplot(data3, line ='45')\n",
    "        plt.title('Group 1 Q-Q Plot')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(5,3))\n",
    "        plt.hist(data3, bins=50, alpha=0.75, color='blue')\n",
    "        plt.title('Returns Distribution')\n",
    "        plt.xlabel('Returns')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    if p_value_normality_group1 < P_VALUE_BENCHMARK:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(N_SAMPLES):\n",
    "    count += normality_test(np.array(rdf2['ReturnPctList'][i]))\n",
    "print(f\"Number of normally distributed returns: {count} / {N_SAMPLES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(N_RANDOM_SAMPLES):\n",
    "    count += normality_test(np.array(random_rdf2['ReturnPctList'][i]))\n",
    "print(f\"Number of normally distributed returns: {count} / {N_SAMPLES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bootstrap_returns(returns, n_bootstraps=100):\n",
    "    \"\"\"Generate bootstrap samples for returns and calculate mean for each sample. Ustilising the Central Limit Theorem\"\"\"\n",
    "    bootstrap_means = np.array([np.mean(np.random.choice(returns, size=len(returns), replace=True)) for _ in range(n_bootstraps)])\n",
    "    return bootstrap_means\n",
    "\n",
    "from scipy.stats import kstest, norm\n",
    "\n",
    "def ks_test_with_theoretical_distribution(bootstrap_means):\n",
    "    \"\"\"Perform KS test comparing bootstrap means with a normal distribution.\"\"\"\n",
    "    # Assuming the theoretical normal distribution has the same mean and std as the bootstrap_means\n",
    "    mean, std = np.mean(bootstrap_means), np.std(bootstrap_means)\n",
    "    return kstest(bootstrap_means, 'norm', args=(mean, std))\n",
    "\n",
    "def nested_ks_test_for_p_values(p_values):\n",
    "    \"\"\"Perform KS test to check if the given p-values are uniformly distributed.\"\"\"\n",
    "    return kstest(p_values, 'uniform')\n",
    "\n",
    "# Mock data: returns for different sentiment analysis techniques\n",
    "returns_data = {\n",
    "    'Technique0': pl\n",
    "    # 'Technique1': np.random.normal(0.05, 0.02, 1000),\n",
    "    # 'Technique2': np.random.normal(0.04, 0.02, 1000),\n",
    "    # Add more techniques as needed\n",
    "}\n",
    "\n",
    "n_bootstraps = 100\n",
    "p_values_for_ks_tests = []\n",
    "\n",
    "for technique, returns in returns_data.items():\n",
    "    # Step 1: Bootstrap\n",
    "    bootstrap_means = bootstrap_returns(returns, n_bootstraps)\n",
    "    \n",
    "    # Step 2: KS Test with Theoretical Distribution\n",
    "    ks_stat, ks_p_value = ks_test_with_theoretical_distribution(bootstrap_means)\n",
    "    print(f\"KS test for {technique}: Stat={ks_stat}, P-Value={ks_p_value}\")\n",
    "    \n",
    "    p_values_for_ks_tests.append(ks_p_value)\n",
    "\n",
    "# Step 3: Nested-KS Test\n",
    "nested_ks_stat, nested_ks_p_value = nested_ks_test_for_p_values(p_values_for_ks_tests)\n",
    "print(f\"Nested KS test: Stat={nested_ks_stat}, P-Value={nested_ks_p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.to_latex(index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
